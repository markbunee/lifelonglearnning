

# 超像素因果推理

[基于神经因果模型的图神经网络因果解释 | SpringerLink --- Graph Neural Network Causal Explanation via Neural Causal Models | SpringerLink](https://link.springer.com/chapter/10.1007/978-3-031-73030-6_23)

《Graph Neural Network Causal Explanation via Neural Causal Models》

主要解决了图神经网络（GNN）可解释性方法中存在的一个根本问题：现有方法大多基于**关联性**，容易受到数据中虚假相关性的干扰，从而可能识别出有偏见的、非因果的解释子图。为此，作者提出了第一个基于因果推断的GNN解释器——**CXGNN**，旨在发现对GNN预测结果有**因果关系**的解释性子图。

论文的研究目的是为了解决现有GNN解释器的核心缺陷。作者指出，一个真正可解释的GNN应该揭示**解释子图与图标签之间的内在因果关系**（因果解释），而不是仅仅找到与预测关联性最强的子图。后者可能只是统计上的巧合（例如，某个 motif 总是与某个标签同时出现，但并非导致该标签的原因），从而误导用户对模型决策的理解。

| 方法类型                 | 代表方法                              | 核心思想                                                     | 与CXGNN对比                                                  |
| :----------------------- | :------------------------------------ | :----------------------------------------------------------- | :----------------------------------------------------------- |
| **基于关联的解释器**     | GNNExplainer, PGM-Explainer, GuidedBP | 通过梯度、扰动或代理模型等方法，找到与预测最相关的子图。     | 这些方法本质上是寻找统计关联，易受虚假相关性影响，无法保证找到真正的因果关系。 |
| **因果启发的解释器**     | GEM, RCExplainer, OrphicX             | 受因果概念（如信息流、注意力机制）启发，试图区分因果和非因果因素。 | 这些方法虽然引入了因果思想，但**本质上并不提供严格的因果解释**，它们推断解释子图的方式仍然是基于关联或启发式规则，而非直接量化节点/边之间的因果效应。 |
| **本文提出的因果解释器** | **CXGNN**                             | 基于因果推断，直接**量化图中节点/边之间的因果效应**，从而识别出因果解释子图。 | **核心创新**，直接建立在结构因果模型和干预之上，旨在提供真正的因果解释。 |

CXGNN的核心思想是：一个图通常由一个**因果子图**（真正导致预测的部分）和一个**非因果部分**（可能引入虚假相关性的部分）组成。该方法通过以下三个主要步骤来识别因果子图：

1. **构建图的因果结构与SCM**：首先，为输入图定义一个以某个参考节点为中心的因果结构。该结构包含了可观测的节点变量和潜在的节点/边效应变量。基于此结构，构建一个结构因果模型（GNN-SCM），为后续的因果干预（intervention）和效应计算提供理论基础。
2. **设计与训练GNN神经因果模型**：在真实的大规模图上直接使用SCM进行因果计算（如do-calculus）在计算上是不可行的。受近期神经因果模型（NCM）的启发，作者设计了一种可训练的、参数化的GNN-NCM来近似GNN-SCM。通过训练这些神经网络，可以高效地估算因果效应。



[SIN: Superpixel Interpolation Network | SpringerLink](https://link.springer.com/chapter/10.1007/978-3-030-89370-5_22)

**开发一种能够无缝集成到下游深度学习任务中的超像素分割方法**。具体来说，它要解决两个现有方法的根本问题：

**传统算法**（如SLIC）基于手工特征，是**不可微分的**，因此无法与深度学习模型一起训练。

**现有的深度学习方法**需要一个**不可微分的后处理步骤**（如处理孤立像素、强制空间连通性），这打断了端到端的训练流程。

论文将现有超像素算法分为两类：

1. **传统算法**：**基于图的方法**：如Normalized Cuts, FH, ERS，将分割视为图划分问题。**基于聚类的方法**：如SLIC及其变体（LSC, Manifold-SLIC, SNIC），使用k-means等算法在颜色和位置空间进行聚类。SNIC是其中少数从开始就强制空间连通性的方法。**局限性**：依赖手工特征，在弱边界上表现不佳，速度慢，且不可微分。
2. **深度学习方法**：**SEAL**：使用网络预测像素亲和力，再输入给基于图的算法生成超像素。**SSN**：将SLIC改造成可微分版本。**FCN**：使用全卷积网络直接预测超像素。**局限性**：上述方法都**需要一个非微分的后处理步骤**来保证超像素的空间连通性，这是端到端集成的主要障碍。

SIN的方法非常新颖，其核心思想是通过**插值**来逐步构建超像素图，并从一开始就保证空间连通性

1. **首个端到端可集成的超像素网络**：SIN是第一个**无需任何非微分后处理**的深度学习超像素分割方法，从根本上解决了端到端集成的瓶颈问题。
2. **创新的插值机制**：通过**水平与垂直插值**的迭代扩展方式，**从第一步开始就强制保证了超像素的空间连通性**。这是方法的核心创新。
3. **高运行效率**：由于移除了后处理步骤，且插值操作高度并行化，SIN速度极快，在GPU上可达约**80fps**，远超其他深度学习方法，满足了实时性需求。

**在SIN算法中，超像素的“块数”（即数量）不是通过聚类多个样本找到的，而是由用户预先设定的一个目标值，算法通过固定的规则来达到这个目标。**

- **传统聚类算法（如SLIC）**：这类算法确实像是在“多个样本（像素点）中寻找”聚类中心。**初始化**：在图像的颜色和位置空间（如5维的[L, a, b, x, y]）随机或规则地初始化K个聚类中心。这里的**K就是目标超像素块数**。**迭代优化**：算法迭代地进行以下两步：**分配**：将每个像素点分配给距离它最近的聚类中心（“在多个样本中寻找归属”）。**更新**：根据分配给每个聚类的所有像素，重新计算聚类中心的位置。直到聚类中心稳定后停止迭代。
- **SIN算法的区别**：SIN**不属于**上述迭代聚类范式。它不计算像素到聚类中心的距离，也不迭代更新中心的位置。它的核心是**通过神经网络预测的关联分数，以类似图像缩放的插值方式，逐像素地决定其归属**，并且通过插值规则天然保证了空间连通性。

| 特征             | SIN (本文方法)                                   | 传统聚类算法 (如 SLIC)                |
| :--------------- | :----------------------------------------------- | :------------------------------------ |
| **块数决定方式** | **用户预设目标值**，通过步长和插值步骤确定性生成 | **用户预设K值**，通过迭代聚类过程逼近 |
| **工作原理**     | 图像插值、图扩展、关联分数预测                   | 迭代聚类（分配-更新）                 |
| **空间连通性**   | 从**第一步开始天然保证**（核心创新）             | 通常需要**后处理**来保证              |
| **是否可微分**   | **是**，可端到端训练                             | **否**，无法集成到深度学习网络中      |

*SIN将复杂的图像结构转化为一组紧凑、连贯的超像素区域。对于淋巴结图像，这意味着能够清晰地分离出淋巴结的不同结构部分。*

**卓越的边界保持能力**：SIN能够紧密贴合淋巴结的复杂边界，确保每个超像素区域内的特征都来自于目标组织，避免了将无关背景或邻近组织的特征混入，这是保证亚类纯净度的关键。

**高紧凑性与平滑性**：SIN生成的超像素非常紧凑和平滑。这意味着它能够有效抑制组织切片内部的噪声和无关细节，更专注于捕捉宏观的组织结构模式，这对于识别具有共性的“亚类”至关重要。如图3所示，SIN在模糊边界上能产生更平滑、更有意义的区域。

 























































