# 1.李宏毅 机器学习

## 1.1 机器学习基本概念

### 0.人工智能

人工智能的技术

机器学习：让计算机再数据中学习从而预测或决定，不需要显式编程

深度学习：使用深层神经网络来模拟大脑的工作方式，特别适合处理大量非结构化的数据

自然语言处理：是计算机能够理解解释和生成人类语言式实现人机交互的技术

机器人学：结合其他领域知识开放自动执行任务的物理设备

### 1.深度学习是什么：

深度学习是机器学习的一个分支，网络由大量节点组成，每个连接都有一个权重，权重代表输入信号的重视程度，调整权重使模型从数据中学习

1.多层结构：多个隐藏层，是的每一层都会提取比前一层更高级的特征

2.自动特征信息：传统机器学习方法需要手动选择特征，深度学习模型能够自动从原始数据中学习有用特征

3.强大表达能力：复杂架构，能够表示非常复杂的函数，对于处理高维数据特别有用。

大数据依赖：需要大量训练数据才能达到最佳性能

5.计算资源需要gpu加速模型的大量矩阵运算



### 2.什么是机器学习：

核心在于构建模型，模型可以从提供的数据集中学习规律和模式，来做预测和决策

机器学习可分为几类：

1.监督学习：模型在一致的输入输出数据集上训练，常见任务分类和回归（房价预测）

2.无监督学习，在没有标签的数据集，发现数据内部的结构和模式，常见任务聚类（数据点分组），降维（减少数据维度同时保留重要信息）和异常检测。

3.半监督学习：介于前两者之间，使用少量标签和大量无标签数据进行训练，减少标注需求

4.强化学习试错学习，互动奖励，广泛应用于游戏机器人导航。

### 3.cox回归分析

比例风险回归模型，用于生存分析某个事件，疾病发生，设备故障个体死亡

独特：同时考虑事件是否发生和发生时间——结局和生存时间

主要特点

1. **处理删失数据**：在生存分析中，经常会遇到删失数据，即某些观测对象在研究结束时仍未发生事件（如病人在研究期间未死亡）。COX回归模型能够有效地处理这类数据。
2. **考虑多个协变量**：COX回归模型可以同时考虑多个自变量（协变量）对生存时间的影响，这有助于控制潜在的混杂因素。
3. **比例风险假设**：COX回归模型基于一个重要的假设，即不同水平的协变量之间的风险比（Hazard Ratio, HR）在随访期间保持恒定。这意味着协变量的影响不会随着时间的变化而改变。
4. **无需指定风险函数的形式**：与其它一些生存分析方法不同，COX回归模型不需要事先指定基础风险函数的具体形式，这使得它更加灵活。
5. ![image-20241010115825819](./image-20241010115825819.png)

自变量即协变量

操作步骤：

1. **数据准备**：整理生存时间和事件发生状态的数据，以及可能影响生存时间的协变量数据。
2. **单变量分析**：可以先通过单变量分析（如Kaplan-Meier生存曲线、Log-rank检验等）初步了解各个协变量与生存时间的关系。
3. **多变量分析**：建立COX回归模型，将所有有意义的协变量纳入模型中，评估它们对生存时间的影响。
4. **模型验证**：检查模型是否满足比例风险假设，以及模型的拟合度和预测准确性。
5. **结果解释**：根据模型输出的风险比（HR）及其置信区间来解释协变量对生存时间的影响。
6. R PYTHON LIFELINES库，sas spss



### 4.c-index（一致性指数）

评估生存分析模型预测性能的常用指标，衡量的是模型预测的生存时间顺序与实际生存时间顺序的一致性程度，0-1越大越好。



### 5.置信区间

是统计学中用来估计总体参数的一个区间估计方法。它提供了一个范围，该范围内包含总体参数真值的概率为某个预先设定的置信水平（Confidence Level）

置信区间不仅给出了参数的估计值，还量化了估计的不确定性。





regression 回归  

classification 分类

structured learning 结构化学习

bias weight loss (0.5K,1)LOSS残差真实减去预测累加

learning rate hyperparameters 自己设置hypervalue 梯度下降![image-20241004222115096](./image-20241004222115096.png)

找w和b![image-20241004222539813](./image-20241004222539813.png)![image-20241004222655706](./image-20241004222655706.png)

model bias![image-20241004223203421](./image-20241004223203421.png)

信号与系统 函数拟合线性相加 逼近 hard sigmoid

![image-20241004224019395](./image-20241004224019395.png)![image-20241004223904788](./image-20241004223904788.png)

## 1.2 深度学习基本概念

![image-20241004224128709](./image-20241004224128709.png)

![image-20241004224319837](./image-20241004224319837.png)

![image-20241004224645857](./image-20241004224645857.png)

![image-20241004224659401](./image-20241004224659401.png)

![image-20241004224843557](./image-20241004224843557.png)

![image-20241004224955919](./image-20241004224955919.png)

cT即转成数

![image-20241004225922828](./image-20241004225922828.png)

![image-20241005095109420](./image-20241005095109420.png)

![image-20241005095522214](./image-20241005095522214.png)

update 更新gradient 

![image-20241005095649598](./image-20241005095649598.png)

![image-20241005095906557](./image-20241005095906557.png)

图像合成研究信号与系统 10.5

![image-20241005100013852](./image-20241005100013852.png)

两倍的relu = sigmoid 最常见的activation function

![image-20241005100145144](./image-20241005100145144.png)

可以反复叠加增加更多参数

many hidden layer ——>neural network -->deep learning

over fitting ：训练变好没训练过的变差，在意没有看过的资料的表现

## 1.3 深度学习相关

perceptron linear model RMB

![image-20241005103000004](./image-20241005103000004.png)

1X1+(-1)X(-2)+1 sigmoid

![image-20241005103417556](./image-20241005103417556.png)

function set

![image-20241005103810569](./image-20241005103810569.png)

residual net

![image-20241005104515257](./image-20241005104515257.png)

![image-20241005104309780](./image-20241005104309780.png)

gpu加速 矩阵运算，有部分gpu有network优化

output layer 分类 feature在hidden layers 中提取

![image-20241005105057951](./image-20241005105057951.png)

vector 

![image-20241005105405302](./image-20241005105405302.png)

256——>10维 设置layers

不是deep的model 要做featrue engering 找一个好的特征

deep的model 则可以pixel 研究怎么抽取特征 设计一个network struct 直接让机器去找feature

NLP 深度学习并没有显著差异 

机器自己去找struct struct自己乱接

![image-20241005110557552](./image-20241005110557552.png)

![image-20241005110733140](./image-20241005110733140.png)

![image-20241005110828445](./image-20241005110828445.png)

![image-20241005111110983](./image-20241005111110983.png)

backpropagation toolkit

![image-20241005111300455](./image-20241005111300455.png)

![image-20241005111436835](./image-20241005111436835.png)

## 1.4 反向传播

backpropagation 计算gradient efficiently 就是gradient decent 的计算方法，拆解公式分开计算

chain relu

![image-20241005112215342](./image-20241005112215342.png)

s改变影响x，y 影响z

mit课程也要补 花书 项目实现

![image-20241005230622002](./image-20241005230622002.png)

c为交叉熵的值

![image-20241005231111498](./image-20241005231111498.png)

backpropagation ：forward pass backward pass

![image-20241005231250467](./image-20241005231250467.png)

![image-20241005231441481](./image-20241005231441481.png)

![image-20241005231921132](./image-20241005231921132.png)

课程：吴恩达 李宏毅 mit 李沐

![image-20241005232251822](./image-20241005232251822.png)

![image-20241005232409659](./image-20241005232409659.png)

找到outlayer一直找到后面的output layer

![image-20241005232914600](./image-20241005232914600.png)

## 1.5 Regression回归

输出预测的可能性，输出值

宝可梦cp值

![image-20241005233557964](./image-20241005233557964.png)

第一步找model 第二步骤评估function，第三步选择最好的function

linear model  x-- >feature

![image-20241006093851759](./image-20241006093851759.png)

![image-20241006094043810](./image-20241006094043810.png)

![image-20241006094155643](./image-20241006094155643.png)

![image-20241006102709822](./image-20241006102709822.png)

带入解出function ，w，b

gradient descent ：

randomly pick, compute w0 梯度下降移动的step为learning rate

![image-20241006103042530](./image-20241006103042530.png)

线性只有一个最小值



trainning 和 testing  

training越复杂找到的error越低前提是gradient descent 找到准确，因为复杂的包含前面的

![image-20241006101529253](./image-20241006101529253.png)

越复杂在testing data 上不一定好，overfitting

第二次改方案

不同种类的model不要一样

![image-20241006102317863](./image-20241006102317863.png)





![image-20241010104906717](./image-20241010104906717.png)

Wi越接近0越平滑，一个比较平滑的function效果会好一些

![image-20241010105316771](./image-20241010105316771.png)

bios只是将其上下移动

在深度学习中回归任务输出的是连续值，预测结果可以取任意实数值，应用于预测具体数值的场景，在输出层一般只有一个神经元，输出预测值。

在使用深度神经网络进行房价预测时，模型的最后一层可能会直接输出一个代表预测价格的数值

常用的损失函数包括

均方误差（Mean Squared Error, MSE）

平均绝对误差（Mean Absolute Error, MAE），这些损失函数帮助评估模型预测值与真实值之间的差异，并指导模型参数的调整以优化预测准确性。

## 1.6 分类

按照regression的方法来做分类

![image-20241010110824981](./image-20241010110824981.png)

![image-20241010110548413](./image-20241010110548413.png)

造成其他部分影响，实际没有关系



![image-20241010111311822](./image-20241010111311822.png)

![image-20241010111449102](./image-20241010111449102.png)

![image-20241010111534727](./image-20241010111534727.png)

二分类是，给一个x判断在那个class中概率最大

![image-20241010111706839](./image-20241010111706839.png)

probability density 不是几率但与几率呈正比

Gaussian Distribution

u   converiance matrix

![image-20241010112234368](./image-20241010112234368.png)

![image-20241010112505504](./image-20241010112505504.png)

![image-20241011225042985](./image-20241011225042985.png)

sample里面没有的就是要计算在1类中或在2类中的gosion

![image-20241013102122795](./image-20241013102122795.png)

Bishop 

![image-20241013102844199](./image-20241013102844199.png)

![image-20241013103322524](./image-20241013103322524.png)

几率低不等于是0 different likelihood

sample的第一个几率到sample到最后一个几率

穷举u 和sigma 

![image-20241013103724983](./image-20241013103724983.png)

![image-20241013103829601](./image-20241013103829601.png)

![image-20241013103937736](./image-20241013103937736.png)

![image-20241013104114162](./image-20241013104114162.png)

共用converiance matrix

![image-20241013110001882](./image-20241013110001882.png)

![image-20241013110055260](./image-20241013110055260.png)

![image-20241013110115182](./image-20241013110115182.png)

![image-20241013110254891](./image-20241013110254891.png)

![image-20241013110535663](./image-20241013110535663.png)

搞出几率再求w和b可不可以直接求出w和b

## 1.7 逻辑回归

vector

![image-20241022223333256](./image-20241022223333256.png)

![image-20241022223419962](./image-20241022223419962.png)

![image-20241022223605936](./image-20241022223605936.png)

![image-20241022223810851](./image-20241022223810851.png)

![image-20241022223903775](./image-20241022223903775.png)

交叉熵cross entropy 求两者

distribution 之间越接近越好

![image-20241022224145503](./image-20241022224145503.png)

class1 和class2 

![image-20241022224418875](./image-20241022224418875.png)

![image-20241022224441336](./image-20241022224441336.png)（nl)==learning rate

x==feature

![image-20241022224645363](./image-20241022224645363.png)

![image-20241022224719263](./image-20241022224719263.png)

![image-20241022225428858](./image-20241022225428858.png)

![image-20241022225850143](./image-20241022225850143.png)

square error 太慢了 使用cross entropy 让training 顺很多 

discriminative generative









## 1.8 机器学习攻略

作业攻略

training data

testing data

![image-20241013122758001](./image-20241013122758001.png)

![image-20241013113427749](./image-20241013113427749.png)

1.先检查trainning data loss结果 

trainning data loss is low

model bias 太简单包含的模型太少找不到

![image-20241013113940852](./image-20241013113940852.png)

1.feature 2.  deeplearning



optimization issue 

local minma gradient decent cannot find it

![image-20241013114604140](./image-20241013114604140.png)

train一些简单的model loss 多少，更加深的或者复杂的包含简单和浅的模型理应更好，前二十层都能做到这么低的loss

![image-20241013114919234](./image-20241013114919234.png)



testing data loss

极端例子

找到一个无用function trainning来说loss是0，但是test就高了

训练资料flexible 

x再训练里输出y x不再就随机

![image-20241013115129016](./image-20241013115129016.png)

数学原理在后面

没有数据资料造成未限制区域freestely

![image-20241013115921404](./image-20241013115921404.png)

data agumentation

合理图片真实世界的影像

![image-20241013120200274](./image-20241013120200274.png)

第二个方法，不要给model太大的弹性

![image-20241013120458564](./image-20241013120458564.png)

![image-20241013120522847](./image-20241013120522847.png)

less parameters 

sharing parameters

模型共用cnn比较没有弹性的model，cnn给了比较大的限制，在影像表现较好

![image-20241013120729633](./image-20241013120729633.png)

不是overfitting

这个限制太大属于model bias

![image-20241013120827252](./image-20241013120827252.png)

什么是模型复杂 模型弹性



![image-20241013121143295](./image-20241013121143295.png)

选择中间合适的



![image-20241013121415310](./image-20241013121415310.png)

testing data 分为public private

public高但是private重要 public不能做标准

![image-20241013122335276](./image-20241013122335276.png)

validation set

![image-20241013122708847](./image-20241013122708847.png)



mismatch

训练资料和测试资料不一样

![image-20241013123102817](./image-20241013123102817.png)

只能看对资料的理解



## 1.9 optimization fails critical point



deep model 并没有表现的更好

![image-20241013155432457](./image-20241013155432457.png)

critical point :

local minima: no way to go

saddle point : escape

![image-20241013160027611](./image-20241013160027611.png)

hessian 二次微分

![image-20241013160131550](./image-20241013160131550.png)

![image-20241013160355381](./image-20241013160355381.png)

特征值确定

H是二阶导数矩阵决定凹凸性

loss对参数的二阶导矩阵，判断矩阵的特征值，有正有负就是鞍点

![image-20241013160740656](./image-20241013160740656.png)

![image-20241013161024436](./image-20241013161024436.png)

![image-20241013161227756](./image-20241013161227756.png)

![image-20241013161402839](./image-20241013161402839.png)

![image-20241013161800318](./image-20241013161800318.png)

从更高的维度去看 三体

一个network neral surfuace

![image-20241013161931185](./image-20241013161931185.png)

local minima少见

很难找到eigen values是正的 

![image-20241013162427077](./image-20241013162427077.png)



![image-20241013162746023](./image-20241013162746023.png)

epoch shuffle 分成多个batch  每个epoch都再分一次每次batch都不一样

![image-20241013163313260](./image-20241013163313260.png)

左，所有examles 看过一遍才更新，走的是稳的

比较准

右边是每一个batch size都计算一遍，走的不稳

![image-20241013163711220](./image-20241013163711220.png)

gpu平行运算能力

所以实际epoch右边更多一个batchsize大的反而要少时间

![image-20241013163854278](./image-20241013163854278.png)

batch size 大trainning表现差

![image-20241013164052818](./image-20241013164052818.png)

![image-20241013164205346](./image-20241013164205346.png)

noisy update 对trainning有帮助

trainning好testing差才是overfitting

![image-20241013164651051](./image-20241013164651051.png)

![image-20241013164759709](./image-20241013164759709.png)

batchsize开很大非常快但是要特殊处理来解决

vanill–> 一般的

![image-20241013165027613](./image-20241013165027613.png)

加上momentum 类似惯性的效果

不只是gradient的反方向加上前一步一起影响

![image-20241013165253107](./image-20241013165253107.png)

用m表示

![image-20241013165336891](./image-20241013165336891.png)

![image-20241013165448965](./image-20241013165448965.png)

error suface

## 1.10 adative learning rate

![image-20241013165724616](./image-20241013165724616.png)

![image-20241013172921442](./image-20241013172921442.png)

![image-20241014225804626](./image-20241014225804626.png)

特质化的learning rate 

坡度大陡峭 learning rate 小一点

坡度小缓慢learning rate 大一点

parameter dependent learning rate

![image-20241014230547878](./image-20241014230547878.png)

![image-20241014230648654](./image-20241014230648654.png)

![image-20241014230747357](./image-20241014230747357.png)

![image-20241014231406958](./image-20241014231406958.png)

Adam：rmspro + momentum

![image-20241015220305322](./image-20241015220305322.png)

gradient很小突然爆炸式不断平均gradient累计很小，走到gradient很大又走回来了，learning rate scheduling 要和时间有关，随时间进行learning rate 减小

![image-20241015220855743](./image-20241015220855743.png)

先变大在变小训练bert时使用的开始0.01然后0.1 一开始的统计时不精准的先让他收集再查找

所有gradient都考虑  sigma momtation都考虑所有 

## 1.11 classification

![image-20241015221958284](./image-20241015221958284.png)

![image-20241017215849002](./image-20241017215849002.png)

得到多个值

softmax y中有任何值，转化带0-1之间

![image-20241015222358016](./image-20241015222358016.png)

![image-20241015222920610](./image-20241015222920610.png)

softmax 两个class会使用sigmoid



![image-20241015224336622](./image-20241015224336622.png)

cross-entropy softmax 绑定分类

自动加softmax

多分类 

cross-entropy 

![image-20241017225758656](./image-20241017225758656.png)

## 1.12 神经网络的压缩

smaller model 

评估参数绝对值对模型的重要性

![image-20241109202645624](./image-20241109202645624.png)

### 1.以参数为单位

### 2.以神经元为单位

以参数为单位的缩小

![image-20241109202758000](./image-20241109202758000.png)

实际操作时

没有加速多少甚至没有加速

以神经元为单位

![image-20241109202937631](./image-20241109202937631.png)

![image-20241109203815285](./image-20241109203815285.png)

![image-20241109203919392](./image-20241109203919392.png)

大的network里面包含了很多小的network

![image-20241109204139979](./image-20241109204139979.png)

![image-20241109204357317](./image-20241109204357317.png)

像石像一样所有的参数都是随机 去掉多余的里面有一个能分类的，

学生要去逼近老师的直接train个大的network来学习

![image-20241109204840742](./image-20241109204840742.png)



### 3.knowledge distillation

teacher告诉student来去学习甚至训练时没见过的内容

![image-20241109205108562](./image-20241109205108562.png)

ensemble

训练多个模型然后输出结果平均或者投票

![image-20241109205247900](./image-20241109205247900.png)

temperature for softmax

![image-20241109205459945](./image-20241109205459945.png)

分类是不变的但是就是让结果更加平滑

network的每一层的去train

大的第十二层对应小的第六层

### 4.parameter quantization

![image-20241109210323908](./image-20241109210323908.png)

压缩参数

![image-20241109210425687](./image-20241109210425687.png)

binary connect

### 5.architecture design network简化

feature map 卷积层中对输入数据进行卷积操作生成的中间表示 捕捉了输入数据的不同特征

#### 特征图的基本概念

1. **输入数据**：通常是一张图像或其他形式的数据。
2. **卷积核（Filter/Kernel）**：一个小的矩阵，用于在输入数据上滑动并执行卷积操作。
3. **卷积操作**：卷积核在输入数据上滑动，每次覆盖一小块区域（称为<u>感受野</u>），并与该区域进行逐元素乘法，然后将结果相加，生成一个标量值。这个标量值就是特征图中的一个像素值。

#### 特征图的生成过程

1. **卷积核的应用**：假设输入数据是一张 5×5  的图像，卷积核大小为 3×3。卷积核在图像上从左到右、从上到下滑动，每次覆盖一个 3×3的区域。
2. **逐元素乘法和求和**：在每个位置，卷积核与覆盖的区域进行逐元素乘法，然后将所有结果相加，生成一个标量值。
3. **生成特征图**：滑动完整个输入图像后，生成一个新的矩阵，这就是特征图。特征图的大小取决于输入图像的大小、卷积核的大小、步幅（Stride）和填充（Padding）等因素。

#### 参数影响

- **步幅（Stride）**：卷积核在输入数据上移动的步长。较大的步幅会导致特征图尺寸减小。
- **填充（Padding）**：在输入数据的边界添加额外的零值，以保持特征图的尺寸不变或控制其变化。
- **卷积核数量**：一个卷积层可以有多个卷积核，每个卷积核生成一个特征图。这些特征图组合在一起形成一个多通道的输出。

#### 特征图的作用

1. **特征提取**：特征图捕捉了输入数据的不同特征，如边缘、纹理等。不同层次的特征图可以捕捉不同级别的特征，浅层特征图通常捕捉局部特征，深层特征图则捕捉更高级的语义特征。
2. **降维**：通过卷积操作，特征图可以有效地减少输入数据的维度，同时保留重要的特征信息。
3. **非线性变换**：卷积操作通常与激活函数（如ReLU）结合使用，引入非线性变换，增强模型的表达能力。

```
输入图像 (5x5):
1 2 3 4 5
6 7 8 9 10
11 12 13 14 15
16 17 18 19 20
21 22 23 24 25

卷积核 (3x3):
-1 0 1
-2 0 2
-1 0 1

特征图 (3x3):
(1*(-1) + 2*0 + 3*1 + 6*(-2) + 7*0 + 8*2 + 11*(-1) + 12*0 + 13*1) = 8
...
最终生成的特征图:
8  10 12
14 16 18
20 22 24``
```

filter

处理信号和图像权重和系数

 在cnn中滤波器也称为卷积核kernel

### 滤波器的基本概念

1. **定义**：滤波器是一组权重，通常以矩阵的形式存在，用于在输入数据上执行特定的操作，如检测边缘、平滑噪声等。
2. **用途**：在图像处理中，滤波器常用于特征提取、降噪、锐化等任务。在深度学习中，滤波器用于提取输入数据的高级特征。

### 滤波器的工作原理

1. **卷积操作**：滤波器通过卷积操作与输入数据交互。具体来说，滤波器在一个小区域内（称为感受野）与输入数据进行逐元素乘法，然后将结果相加，生成一个标量值。
2. **滑动窗口**：滤波器在输入数据上滑动，每次覆盖一个小区域，生成一个标量值，这些标量值组合成一个新的矩阵，即特征图。

### 滤波器的参数

1. **大小**：滤波器的大小通常表示为 k×k*，其中 k是一个奇数，常见的大小有 3×3 和 5×5。
2. **步幅（Stride）**：滤波器在输入数据上移动的步长。较大的步幅会导致特征图尺寸减小。
3. **填充（Padding）**：在输入数据的边界添加额外的零值，以保持特征图的尺寸不变或控制其变化。
4. **数量**：一个卷积层可以有多个滤波器，每个滤波器生成一个特征图。这些特征图组合在一起形成一个多通道的输出。

### 滤波器的类型

1. **高斯滤波器**：用于平滑图像，减少噪声。
2. **Sobel滤波器**：用于检测图像中的边缘。
3. **拉普拉斯滤波器**：用于检测图像中的二阶导数，常用于边缘检测。
4. **自适应滤波器**：根据输入数据动态调整滤波器的权重。

### 深度学习中的滤波器

在卷积神经网络中，滤波器的权重通常通过反向传播算法进行训练，以优化网络的性能。每个卷积层的滤波器可以学习到不同的特征，例如：

- **浅层滤波器**：通常学习到简单的特征，如边缘和纹理。
- **深层滤波器**：学习到更复杂的特征，如形状和物体部分。

![image-20241109211020395](./image-20241109211020395.png)

depthwise separable convolution

![image-20241109212901250](./image-20241109212901250.png)

























## 1.13 NEW OPTIMIZATION

Optimitation for deep learning

它可以是x丢进算出来的y接近yhead

1.SGD

![image-20241017231846836](./image-20241017231846836.png)

SGD WITH MOMENTUM       2.SGDM

![image-20241017231914299](./image-20241017231914299.png)

有个多次累计的量不会停止

3.Adagrad

![image-20241017232147469](./image-20241017232147469.png)

4.RMSProp

确保他在时间上有一定的变化

![image-20241017232308608](./image-20241017232308608.png)

5.Adam

SGDM+RMSProp

![image-20241017232448173](./image-20241017232448173.png)

AMSGrad

AdaBound

![image-20241018220644404](./image-20241018220644404.png)

工程方法可能不是最好方法

SGDM如何提升呢

several epoch

SGDR 三角波函数来调整

adam 

![image-20241018221709489](./image-20241018221709489.png)

![image-20241018221753768](./image-20241018221753768.png)

NAG

## 1.14 CNN

卷积神经网络convolutional neural network

dimention长度代表种类数

上万种lable就有上万种

image classification

![image-20241023231319549](./image-20241023231319549.png)

三维 channel rgb三种演示 tensor拉直

将图片变成向量 pixel强度每一维度数字

![image-20241023231535621](./image-20241023231535621.png)

参数过多 增加了模型的弹性 弹性越大越容易overfitting

![image-20241023231728903](./image-20241023231728903.png)

fully connected network 

检查pattern

patten综合来决定不需要整张完整图片去输入

![image-20241023231932577](./image-20241023231932577.png)

简化

receptive field 感受野 拉直

彼此重叠

![image-20241023232203360](./image-20241023232203360.png)

希望receptive field 高度重叠 防止遗漏

kernel size padding  overlap stride 

![image-20241023232705523](./image-20241023232705523.png)

![image-20241023232813218](./image-20241023232813218.png)

守备范围不一样 但是重复工作

共享参数 

![image-20241023233023252](./image-20241023233023252.png)

weight完全是一样的，范围不一样

![image-20241027101027445](./image-20241027101027445.png)

![image-20241027100739515](./image-20241027100739515.png)

为影像设计cnn 

强制一个范围弹性变小 参数一样

![image-20241027111311978](./image-20241027111311978.png)

![image-20241027111348581](./image-20241027111348581.png)

filters高度就是要处理channel的深度

![image-20241027111509969](./image-20241027111509969.png)

![image-20241027111547421](./image-20241027111547421.png)

![image-20241027111601119](./image-20241027111601119.png)

![image-20241027111702750](./image-20241027111702750.png)

filter扫描整张图片 neuron共用参数

pooling

![image-20241027111909891](./image-20241027111909891.png)

convolution和pooling交替

pooling的目的是降低计算量

![image-20241027112007396](./image-20241027112007396.png)

把排成矩阵的拉直成向量

![image-20241027112122891](./image-20241027112122891.png)

19*19的图片每个像素位置都按48个位置

48个channel19*19 *48

![image-20241027112547076](./image-20241027112547076.png)

cnn在影像上很好cnn不能辨识图像放大缩小旋转，拉伸后向量数据变化，所以要在数据预处理也要改

![image-20241027112924727](./image-20241027112924727.png)

理想和现实的差距 candidate over fitting会大

validation set大小 hval太复杂 

loss很低 但是现实和理想和接近 

深度学习让鱼和熊掌兼得

![image-20241027113508774](./image-20241027113508774-1730000109809-1.png)

![image-20241027113520290](./image-20241027113520290.png)

深度学习反而不会overfitting

![image-20241027113603940](./image-20241027113603940.png)

高瘦参数量反而少

较少参数反而不会overfitting

逻辑电路

![image-20241027113705075](./image-20241027113705075.png)

![image-20241027113716333](./image-20241027113716333.png)



![image-20241027113728552](./image-20241027113728552.png)

![image-20241027114027779](./image-20241027114027779.png)

![image-20241027114250380](./image-20241027114250380.png)

![image-20241027114357623](./image-20241027114357623.png)

## 1.15 spatial Transformer

CNN IS INvariant to scaling and rotataion

![image-20241027200535640](./image-20241027200535640.png)

feature map

![image-20241027200729848](./image-20241027200729848.png)

weight设计旋转

![image-20241027200833744](./image-20241027200833744.png)

评议旋转

![image-20241027200934328](./image-20241027200934328.png)

![image-20241027201009994](./image-20241027201009994.png)

![image-20241027201250543](./image-20241027201250543.png)

![image-20241027201413989](./image-20241027201413989.png)

compose gradient小小变化output的变化

无法gradient decent

interpolation

![image-20241027202046493](./image-20241027202046493.png)

![image-20241027202139525](./image-20241027202139525.png)

![image-20241027202314055](./image-20241027202314055.png)

![image-20241027202556276](./image-20241027202556276.png)

![image-20241027202727247](./image-20241027202727247.png)

相当于放大来看

## 1.16 self-attention

经典模块

![image-20241027202932758](./image-20241027202932758.png)

句子改为向量

![image-20241027203049820](./image-20241027203049820.png)

一段改为向量

每一个节点可以是一个向量

![image-20241027203119128](./image-20241027203119128.png)

![image-20241027203144369](./image-20241027203144369.png)

pos tagging

输出的三种可能性

第一种可能的输出 输入和输出一致

五个向量输出五个label

![image-20241027203442135](./image-20241027203442135.png)

第二种可能的

一整个输出一个label

确定谁讲的

确定分子亲水性

![image-20241027203423706](./image-20241027203423706.png)

第三种输出

机器自己决定输出多少个label

sequence to sequence

![image-20241027203758178](./image-20241027203758178.png)

![image-20241027204005087](./image-20241027204005087.png)

sequence有长有短开的window会增加计算量

![image-20241027204121260](./image-20241027204121260.png)

多次self-attention再次考虑整个sequence在处理一次

transformer中有个modle self attention

![image-20241027204346219](./image-20241027204346219.png)

计算attention数值评估向量间的关系

![image-20241027204620888](./image-20241027204620888.png)

最常见的方法dot-product

![image-20241027210732563](./image-20241027210732563.png)

![image-20241027210804476](./image-20241027210804476.png)

![image-20241027210952808](./image-20241027210952808.png)

![image-20241027211023198](./image-20241027211023198.png)

![image-20241027211612944](./image-20241027211612944.png)

![image-20241027211843861](./image-20241027211843861.png)

![image-20241027212116378](./image-20241027212116378.png)

![image-20241027212317685](./image-20241027212317685.png)

![image-20241027212949343](./image-20241027212949343.png)

self-attention -->mult-head self-attention

![image-20241027213950814](./image-20241027213950814.png)

![image-20241027213959234](./image-20241027213959234.png)

self attention for speech

![image-20241028193225289](./image-20241028193225289.png)

语音辨识truncated self attention

vector set tensor channel pixel 三维向量

![image-20241028193356511](./image-20241028193356511.png)

self attention gan 处理图片

![image-20241028193432213](./image-20241028193432213.png)

self-attention and cnn

![image-20241028193537833](./image-20241028193537833.png)

![image-20241028193558424](./image-20241028193558424.png)

self-attention更加灵活

![image-20241028193645383](./image-20241028193645383.png)

训练资料多时候cnn没有太多优势

![image-20241028193950652](./image-20241028193950652.png)

output考虑前面的就是把前面的数据存储下来

selfattention平行运算运算速度selfattention更高级

selfattention用到graph

note的关联self-attention确定note 的关联性没有相连可能没有关系

![image-20241028194320662](./image-20241028194320662.png)

self-attention的变形最大缺点是运算量大

速度快那么performece会下降

深度学习尤其是transfomer模型中 实现注意力机制

### 基本概念

- **Query（查询）**：代表我们正在寻找的信息或焦点。在文本处理中，这通常对应于当前正在处理的词或句子片段。

- **Key（键）**：代表文档中所有其他词或句子片段的信息，用于与Query进行匹配，以判断其相关性。

- **Value（值）**：如果某个词或句子片段与Query高度相关，那么它的Value将被用来构建最终的输出。Value携带了该词的实际内容或信息。

  ### 工作原理

  1. **生成Q、K、V向量**：首先，原始输入数据（例如一句话中的每个词）会被转换成三个向量：Query向量、Key向量和Value向量。这通常是通过线性变换（即乘以权重矩阵）完成的。

  2. **计算注意力分数**：接下来，使用Query向量与所有Key向量进行点积运算，得到每个位置上的注意力分数。这些分数反映了每个位置上的词与当前Query的相关性。

  3. **应用Softmax函数**：为了确保所有注意力分数之和为1，通常会对这些分数应用Softmax函数，这样可以得到一个概率分布，表示每个位置的重要性。

  4. **加权求和Value向量**：最后，利用上一步得到的概率分布作为权重，对所有的Value向量进行加权求和，生成最终的输出向量。这个输出向量综合了所有与Query相关的词的信息。

     假设有一个简单的句子：“猫坐在椅子上”。我们想计算“猫”这个词的注意力输出。

     1. **生成Q、K、V向量**：对于“猫”，生成其Query向量；对于句子中的每一个词（包括“猫”本身），生成各自的Key向量和Value向量。
     2. **计算注意力分数**：计算“猫”的Query向量与每个词的Key向量之间的点积，得到注意力分数。
     3. **应用Softmax函数**：对上述得到的注意力分数应用Softmax函数，得到每个词的重要性权重。
     4. **加权求和Value向量**：使用Softmax后的权重对每个词的Value向量进行加权求和，得到“猫”这个词的注意力输出。

## 1.17 recurrent neural network

input是一个词汇，用一个向量来表示

![image-20241028194723535](./image-20241028194723535.png)

![image-20241028194755819](./image-20241028194755819.png)

![image-20241028194857469](./image-20241028194857469.png)

带记忆的neural network RNN

![image-20241028195353466](./image-20241028195353466.png)

![image-20241028195437007](./image-20241028195437007.png)

![image-20241028195517343](./image-20241028195517343.png)

Can be deep 

![image-20241028195552598](./image-20241028195552598.png)

elman network and jordan network

![image-20241028195633328](./image-20241028195633328.png)

![image-20241028195738809](./image-20241028195738809.png)

network 看了所有input相当于看了整个sequence



network自己学到

![image-20241028195954111](./image-20241028195954111.png)

四个input 唯一一个output 

记忆被挤掉menmory  还是很短

![image-20241030000238849](./image-20241030000238849.png)

input三维vector output 一维的值

![image-20241030000359347](./image-20241030000359347.png)

-1 1 0确定输入输出

![image-20241030000658822](./image-20241030000658822.png)

![image-20241030171728339](./image-20241030171728339.png)

要操作另外三个gate 4倍于一般的nural network

![image-20241030171948028](./image-20241030171948028.png)

四个vector操作memory的操作

hidden layyer输入进来

加入peephole

![image-20241030172310868](./image-20241030172310868.png)

standard

![image-20241030172430214](./image-20241030172430214.png)

clipping当gradient大于15就等于15结束

![image-20241031171406817](./image-20241031171406817.png)

![image-20241031171650101](./image-20241031171650101.png)

rnn的数据再反复使用，有时会很大有时会很小，同一个数据再不同时间点被使用

有什么技巧解决这个问题

lstm可以解决vanishing问题 memeroy会被洗掉 lstm留存影响 

![image-20241102214652303](./image-20241102214652303.png)

只有去除掉旧的值才能加新值

![image-20241102214743611](./image-20241102214743611.png)

![image-20241102214928857](./image-20241102214928857.png)

![image-20241102215010445](./image-20241102215010445.png)

![image-20241102215958023](./image-20241102215958023.png)

ctc即使训练中没有遇到也可能辨识出来

![image-20241102220116137](./image-20241102220116137.png)

推文接龙要断开才停

![image-20241102220954177](./image-20241102220954177.png)

![image-20241102222552925](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20241102222552925.png)

每一个句子变成vector

 ![image-20241102222801551](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20241102222801551.png)

![image-20241102222942515](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20241102222942515.png)

RNN attention-based model 都要使用记忆

![image-20241102223147951](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20241102223147951.png)

neural turing machine 讨论也会记忆下来

最重要都是deep

![image-20241102224521745](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20241102224521745.png)

vuterbi 值来修改连续突出几个label，

deep learning 和struct learning结合

![image-20241102224757647](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20241102224757647.png)

![image-20241102225205930](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20241102225205930.png)

HMM自动调整 让rnn发现错误要structure learning才能做到

![image-20241105191727953](./image-20241105191727953.png)

![image-20241105191827151](./image-20241105191827151.png)

segement转成vector

![image-20241105194953759](./image-20241105194953759.png)

![image-20241105195051651](./image-20241105195051651.png)

![image-20241105195316073](./image-20241105195316073.png)

![image-20241105195446766](./image-20241105195446766.png)

![image-20241105195653334](./image-20241105195653334.png)





## 1.18 几种神经网络架构

### 1. RNN (Recurrent Neural Network)

- **特点**：
  - **序列数据处理**：RNN 适用于处理序列数据，如文本、语音和时间序列数据。
  - **记忆机制**：RNN 通过隐藏状态（hidden state）来捕捉序列中的依赖关系。
  - **变体**：常见的变体包括 LSTM（Long Short-Term Memory）和 GRU（Gated Recurrent Unit），这些变体解决了传统 RNN 的梯度消失问题。
- **应用场景**：
  - **自然语言处理**：文本生成、情感分析、机器翻译。
  - **语音识别**：语音转文字、语音合成。
  - **时间序列预测**：股票价格预测、天气预报。

### 2. CNN (Convolutional Neural Network)

- **特点**：
  - **局部连接**：CNN 通过卷积层捕捉局部特征，适合处理图像数据。
  - **共享权重**：卷积核在图像的不同位置共享权重，减少了参数数量。
  - **池化层**：通过池化层（如最大池化、平均池化）降低特征图的维度，减少计算量。
- **应用场景**：
  - **计算机视觉**：图像分类、目标检测、图像分割。
  - **视频处理**：动作识别、视频分类。
  - **医学影像**：病变检测、组织分割。

### 3. GNN (Graph Neural Network)

- **特点**：
  - **图结构数据**：GNN 适用于处理图结构数据，如社交网络、分子结构、知识图谱。
  - **消息传递**：通过节点之间的消息传递机制，捕捉节点之间的依赖关系。
  - **聚合函数**：使用聚合函数（如求和、平均、最大值）来更新节点的表示。
- **应用场景**：
  - **社交网络分析**：社区检测、影响力传播。
  - **推荐系统**：基于图的推荐算法。
  - **化学和生物学**：分子性质预测、蛋白质结构预测。

### 4. Transformer

- **特点**：
  - **自注意力机制**：Transformer 使用自注意力机制（Self-Attention）来捕捉序列中的长距离依赖关系。
  - **并行计算**：相比 RNN，Transformer 可以并行处理输入序列，提高了训练速度。
  - **多头注意力**：通过多头注意力机制，Transformer 可以从多个角度捕捉序列中的信息。
- **应用场景**：
  - **自然语言处理**：机器翻译、文本生成、问答系统。
  - **语音处理**：语音识别、语音合成。
  - **推荐系统**：基于序列的推荐算法



## 1.19 Meta Learning

与machine learning已经有区别了，调参数，hyperparameter

现在业界就是调hyperparameter来多次一起调出最好的参数

meta learning就i是想要解决机器自己学习参数

![image-20241030173951111](./image-20241030173951111.png)

![image-20241030174031486](./image-20241030174031486.png)

meta learning 学习学习

![image-20241031111023221](./image-20241031111023221.png)

![image-20241031111039486](./image-20241031111039486.png)

![image-20241031154517297](./image-20241031154517297.png)

用训练里面的测试资料来检查

![image-20241031154842436](./image-20241031154842436.png)

![image-20241031155008510](./image-20241031155008510.png)

![image-20241031155141082](./image-20241031155141082.png)

训练资料学出来一个训练分苹果和橙子

测试资料的训练资料出来classify然后用test去测试futrelearning 和meta learning 

![image-20241031160235170](./image-20241031160235170.png)



![image-20241031160312676](./image-20241031160312676.png)

![image-20241031160354597](./image-20241031160354597.png)

![image-20241031160610206](./image-20241031160610206.png)

![image-20241031160808560](./image-20241031160808560.png)

development task来挑参数

 develop task与testing task 常使用调参

meta learning什么可以被学习到

![image-20241031161952759](./image-20241031161952759.png)

![image-20241031162123955](./image-20241031162123955.png)

![image-20241031162342588](./image-20241031162342588.png)

maml有标记资料

![image-20241031162459048](./image-20241031162459048.png)

吧多个资料放到一起

MAML PRE-TRAINING区别

![image-20241031165920541](./image-20241031165920541.png)

![image-20241031170018600](./image-20241031170018600.png)



## 1.20 Graph Neaurl network

graph

data之间有关系

![image-20241105200232032](./image-20241105200232032.png)

classifier 分类

![image-20241105200429397](./image-20241105200429397.png)

![image-20241105200625311](./image-20241105200625311.png)

![image-20241105201155160](./image-20241105201155160.png)

有最后一个输出出来

![image-20241105201254347](./image-20241105201254347.png)

![image-20241105201316287](./image-20241105201316287.png)

feature拍起来拍成一个矩阵

![image-20241105201515523](./image-20241105201515523.png)



GraphSAGE



## 1.21 Transformer

![image-20241105202027589](./image-20241105202027589.png)

模型输入声音输出文字语音辨识

输入文字输出语言就是语音合成

sequence to sequence 

训练聊天机器人

![image-20241105202337519](./image-20241105202337519.png)

question answering 

![image-20241105202545006](./image-20241105202545006.png)

![image-20241105202736525](./image-20241105202736525.png)

grammar as a foreign language

multi-label classification

![image-20241105202938283](./image-20241105202938283.png)

multi-class classification

就是一篇文章可以属于多个class 每篇文章对应的class都不一样

硬来机器自己决定多少class sequence to sequence 硬解

![image-20241105203139775](./image-20241105203139775.png)

![image-20241105203212626](./image-20241105203212626.png)

encoder

![image-20241106173153001](./image-20241106173153001.png)

![image-20241106173310549](./image-20241106173310549.png)

![image-20241106173337404](./image-20241106173337404.png)

![image-20241106173434774](./image-20241106173434774.png)

seq2seq

encoder inputsequence  decode sequence

self attention fc fully conneted

vector 还要拉上input residual connetion input直接跟output加起来组成一个新的vector 



residual还来要在做一次normal次啊是最终的block 

bert其实就是transformer的encoder 

![image-20241106174020774](./image-20241106174020774.png)

encoder--decoder

输出的distribution 加起来会是一

![image-20241106174415252](./image-20241106174415252.png)

向量给每个文字一个分数分数最高的即输出出来 softmax 

![image-20241106174939691](./image-20241106174939691.png)

![image-20241106175149078](./image-20241106175149078.png)

![image-20241106213813787](./image-20241106213813787.png)

![image-20241106214049435](./image-20241106214049435.png)

masked 不一样的地方 self attention vector要看过所有的讯息才分析 mask的不同点就是不能去考虑后面的智能考虑前面位置的

![image-20241106214223440](./image-20241106214223440.png)

decoder输出是只能输出前面的东西

一个一个产生和selfattention不一样，selfattention是全部输入 

![image-20241106214444293](./image-20241106214444293.png)

![image-20241106214525533](./image-20241106214525533.png)

![image-20241106214544677](./image-20241106214544677.png)

![image-20241106214616592](./image-20241106214616592.png)

![image-20241106214737755](./image-20241106214737755.png)

nat 是一个步骤同时全部生成 没有selfattention 之前是没有nat decoder

classify输出调整 平平行化是最大优势

NAT 

encoder和decoder是如何传讯的

![image-20241106215127341](./image-20241106215127341.png)

cross attention 

![image-20241106215447289](./image-20241106215447289.png)

attention分数为横轴 

![image-20241106215606075](./image-20241106215606075.png)

训练部分

![image-20241106220700031](./image-20241106220700031.png)

每次decoder在产生一个文字是就是做了一次分类 编码器解码器

![image-20241106220820060](./image-20241106220820060.png)

![image-20241106221107421](./image-20241106221107421.png)

decoder输的是准确答案 encoder 给到准确答案给他 中间有个mismatch

teaching forcing

![image-20241106221245556](./image-20241106221245556.png)

copy mechanism 

![image-20241106221419378](./image-20241106221419378.png)

强波他把每个东西都看到

语音辨识语音合成 guided attention

![image-20241106221659430](./image-20241106221659430.png)

![image-20241106221836217](./image-20241106221836217.png)

由左念到右 胡乱看

monotonic attention location-aware attention 

beam search 每一次decoder都是选择分数高的那一个 每次找最高的分数来输出 

红色开始好最后不好，绿色开始坏后面好

有时有用有时不好用 

![image-20241106222458713](./image-20241106222458713.png)

训练时加一些nose 在测试时也要杂碎竖脊性 期待decoder 的随机性 随机结果反而好

![image-20241106222606261](./image-20241106222606261.png)

遇到optimizing 难题 当成rl硬做

![image-20241106222649855](./image-20241106222649855.png)

![image-20241106222656285](./image-20241106222656285.png)

scheduled sampling 

## 1.22 机器学习的可解释性

模型  结果不如预期 调架构 调learning rate

linear model 解释能力比较强 不容易被解释 

expainable             interpretable

decison tree 

random forest

expliation 

![image-20241107172427622](./image-20241107172427622.png)

conponet 确定一个重要的区域重要性  

![image-20241107172547757](./image-20241107172547757.png)

用灰色方块去检测 

![image-20241107172658844](./image-20241107172658844.png)

![image-20241107173025954](./image-20241107173025954.png)

expain的意义是人去看

![image-20241107173213973](./image-20241107173213973.png)

![image-20241107173257498](./image-20241107173257498.png)

![image-20241107173438285](./image-20241107173438285.png)

![image-20241107173631251](./image-20241107173631251.png)

network 降嗯吧ending去训练可以回复到原来的声音

![image-20241107173740391](./image-20241107173740391.png)

![image-20241107214735380](./image-20241107214735380.png)

![image-20241107214836662](./image-20241107214836662.png)

![image-20241107214944165](./image-20241107214944165.png)

![image-20241107215054428](./image-20241107215054428.png)

adversarial attack

加上更多限制，把限制加到optimization  

image generator

![image-20241107215836911](./image-20241107215836911.png)

![image-20241107220017042](./image-20241107220017042.png)

![image-20241107220155315](./image-20241107220155315.png)

### 全局解释

关注模型整体的行为模型，旨在提供一个模型在整个输入控件的行为概览，对哪些特征最敏感，哪些挑战对预测结果影响最大。  

全局解释有助于理解模型的一般工作原理，对于模型的选择和优化非常重要。

模型开发阶段

### 局部解释

特定实例的决策过程，提高模型的透明度和可解释性专注于单个预测或一小部分预测的具体细节，试图解释为什么模型会对特定输入产生特定输出。

。局部解释可以帮助用户理解模型对特定实例的决策过程，对于提高模型的透明度和可解释性特别有用。

多地应用于模型部署后，特别是当模型的决策直接影响到个人或组织时，如贷款审批、医疗诊断等，能够增强用户对模型的信任度。



### 实现方法

特征重要性评分 评估特征对模型预测的整体贡献 

部分依赖图 展示一个或多个特征变化影响模型的预测 全局解释

lime 围绕特定样本构建监督的代理模型来提高局部解释

shap 局部和全局 计算特征对预测结果的平均贡献来衡量重要性

## 1.23 人类的攻击

![image-20241107221830835](./image-20241107221830835.png)

![image-20241107222314572](./image-20241107222314572.png)

加入杂讯 

![image-20241107222626038](./image-20241107222626038.png)

![image-20241107223743445](./image-20241107223743445.png)

把人类感知考虑进来第一个是都有改变差别分布到每一个像素上了l infinity

第二个是只有一个改变极大

attack approach

![image-20241107224506305](./image-20241107224506305.png)

![image-20241107224526652](./image-20241107224526652.png)

![image-20241107224607439](./image-20241107224607439.png)

x只能存在在框框内部

![image-20241107224713488](./image-20241107224713488.png)

FGSM

取个sin 要么正一要么负一

![image-20241107224856815](./image-20241107224856815.png)



![image-20241107224938108](./image-20241107224938108.png)

括号内部值大于0去负一

没有目标的

有目标的攻击

white box attack

black box attack 不知道模型参数的攻击

![image-20241109170408874](./image-20241109170408874.png)

丢进去输出资料，然后再将输入输出资料拿去再训练个模型 攻击准确率越低越成功

non target还行

对角线是黑箱攻击

![image-20241109170733866](./image-20241109170733866.png)



在蓝色块都会被辨识成小丑鱼

来自资料少可能

![image-20241109170957252](./image-20241109170957252.png)

![image-20241109171100489](./image-20241109171100489.png)

对一个像素区域来更改

![image-20241109171215408](./image-20241109171215408.png)

找到一个noise去干扰

其他类似资料也会出现 模拟语音

![image-20241109171351583](./image-20241109171351583.png)

物理欺骗 

![image-20241109171617356](./image-20241109171617356.png)

![image-20241109171712999](./image-20241109171712999.png)

![image-20241109171759977](./image-20241109171759977.png)

adversarial reprogramming

按照操作做不是原来训练的事情都是从测试阶段去攻击

从训练时就展开攻击

![image-20241109172038849](./image-20241109172038849.png)

有张下过毒的图片 开后门的方法 不过模型也有限制并不是每个都可以当前

passive defense 

![image-20241109172208736](./image-20241109172208736.png)

加个简单的模糊化攻击的讯号是非常特殊的模糊化就改变了，模糊也会造成许多副作用

![image-20241109172310388](./image-20241109172310388.png)

把影像进行压缩然后失真

![image-20241109172420689](./image-20241109172420689.png)

输出要与输入非常接近训练时没有杂讯对比就会忽视

![image-20241109172513566](./image-20241109172513566.png)

一张图片输入进来进行随机变化来挡住别人的攻击 

主动攻击 proactive defense

训练时就提高防御

![image-20241109172637568](./image-20241109172637568.png)

将识别错误的被攻击的图片重新给一个lable

然后训练

![image-20241109172716899](./image-20241109172716899.png)

先训练然后找漏洞然后再加进去训练

中国算是数据增强增加数据集数量

![image-20241109172803145](./image-20241109172803145.png)

需要较大的训练资料adversarial trainnig for free

## 1.24 自编码器

![image-20241109173131456](./image-20241109173131456.png)

不用标注的方法 不需要lable data 

self supervised 或者pretrain

encoder decode 

确保向量越接近越好 输入结果和重建结果越接近越好

![image-20241109173507754](./image-20241109173507754.png)

像这样的encoder 叶称为 embadding

![image-20241109173547375](./image-20241109173547375.png)

dimension reduction pca t-sne

变化类型可能是有限的

![image-20241109173754906](./image-20241109173754906.png)

降维![image-20241109173819082](./image-20241109173819082.png)

之前的信念是把每一层都分开train

pretrain 的pretrain

![image-20241109173941623](./image-20241109173941623.png)

de-noising auto-decoder

把杂讯去掉

![image-20241109174046843](./image-20241109174046843.png)



![image-20241109174106492](./image-20241109174106492.png)

![image-20241109174555669](./image-20241109174555669.png)



![image-20241109174603395](./image-20241109174603395.png)

![image-20241109193816358](./image-20241109193816358.png)

语音内容 语音特征

![image-20241109193857449](./image-20241109193857449.png)

![image-20241109195547411](./image-20241109195547411.png)

voice converion

discrete representation

一排向量算个相似度

![image-20241109200719701](./image-20241109200719701.png)

![image-20241109201005510](./image-20241109201005510.png)

![image-20241109201141211](./image-20241109201141211.png)



![image-20241109201216560](./image-20241109201216560.png)

![image-20241109201247434](./image-20241109201247434.png)

![image-20241109201439027](./image-20241109201439027.png)

anomaly detection 异常检测

只有一个类别 都是没有办法使用分类器

![image-20241109201607793](./image-20241109201607793.png)

输入进去没由办法还原回去 检测是不是训练时刊过的同类型的东西

## 1.26 pointer network

![image-20241109214935965](./image-20241109214935965.png)

![image-20241109215041490](./image-20241109215041490.png)

![image-20241109220942983](./image-20241109220942983.png)

硬train硬发

![image-20241109221018162](./image-20241109221018162.png)

![image-20241109221256188](./image-20241109221256188.png)

从repose中选择部分去贴到上面

pointernetwork 特别适合输入输出都是序列的问题 解决组合优化 如旅行商问题和最小生成树问题

指针网络的核心是注意力机制，它用于生成输出序列中的每个元素。注意力机制允许模型在每个时间步骤关注输入序列中的不同部分。

1. **编码器**：使用一个双向循环神经网络（RNN）或长短期记忆网络（LSTM）对输入序列进行编码，生成每个输入元素的隐藏状态（隐向量）。
2. **解码器**：使用另一个RNN或LSTM作为解码器，生成输出序列。在每个解码步骤中，解码器生成一个查询向量（Query Vector）。
3. **注意力机制**：将解码器生成的查询向量与编码器生成的所有隐向量进行比较，计算注意力分数。这些分数通常通过softmax函数归一化为概率分布，表示每个输入元素被选中的概率。
4. **输出生成**：根据注意力概率分布，选择概率最高的输入元素的索引作为当前时间步骤的输出。然后，将该索引反馈给解码器，继续生成下一个输出元素，直到生成整个输出序列。









## 1.25 NON-auto regressive sequence generation

![image-20241109174936985](./image-20241109174936985.png)

他会是每张图片的平均













# 2. 丁香医生人工智能医学影像组学

影像组学做生存分析 临床特征扩充

![image-20241105232606716](./image-20241105232606716.png)

心电 疾病类型 记忆与细胞 预后诊断 

特征工程

# 3. 西瓜书 周志华

反复读吃透李沐花书，西瓜书 国外话术 多吃论文 

机器学习

科学 技术 工程 应用

机器学习利用经验数据对未来数据进行分析 

典型的机器学习过程 

类别标记 label 标签 

![image-20241106000030742](./image-20241106000030742.png)

![image-20241106000210878](./image-20241106000210878.png)

p是不是等于np 多项式时间复制度 np困难问题之外 

概率近似正确 

## 基本术语

