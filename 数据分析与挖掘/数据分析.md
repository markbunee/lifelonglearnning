# Numpy

\#ndmin 确定维度
\#dtype 显示确定数据类型
\#ndaarray对象
import numpy as np
a = np.array([1,2,3],[3,4,5],ndmin = 2,dtype = complex)
print(a)

\#数据类型
'''
数据类型
int
uint
flaot
complex

'''
array = np.array([1,2,3],[2,3,4])
print('number of dim:',array.ndim) #多少维度二维
print('shape:',array.shape) #两行三列
print('size',array.size) #元素个数6

\#基础运算
a = np.array([1,2,3])
b = np.arange(3)
print(a+b)
print(a-b)
print(a*b)
c = 10 * np.sin(a)
print(c)
print(a<3)
c_dot = np.dot(a,b)
c_dot = a.dot(b)

print(c_dot)
print(np.sum(a,axis = 1))
print(np.mean(a))
print(np.std(a))

\#numpy 索引
a =np.arange(3,15).reshape((3,4))
print(a[1,2])
\#print(a[1][2])
\#只有迭代行
for column in a.T:
print(column)
print(a.flatten()) #将三行四列展平
\#输出元素
for column in a.flat:
print(column)

\#array 的合并
a = np.array([1,2,3])
b = np.array([2,3,4])
c = np.vstack((a,b)) #vertical stack
print(c)
print(np.hstack((a,b))) #horizontal stack
\#纵向合并
print(a[np.newaxis,:])
c = np.concatenate((a,b),axis = 0)
\#分割
\#split只能等分
print(np.split(a,2,axis = 1))
print(np.hsplit(a,2)) #纵向分割
print(np.vsplit(a,2)) #横向分割
print(b is a)

\#copy
\#在numpy中a=b 会关联在一起
\#浅拷贝只拷贝值
b = a.copy()



\#numpy 广播
\#dtype
\#int8, int16, int32, int64
\# 四种数据类型可以使用字符串
\# 'i1', 'i2','i4','i8'
'''
'<i4' 可以分为三部分：

<: 表示字节顺序（Byte Order）。
< 表示小端模式（Little-Endian），即低位字节存储在内存的低地址处。
\> 表示大端模式（Big-Endian），即高位字节存储在内存的低地址处。
如果没有指定字节顺序，默认使用本机的字节顺序（通常是小端模式）。
i: 整数（integer）
u: 无符号整数（unsigned integer）
f: 浮点数（float）
c: 复数（complex）
S: 字节字符串（bytes string）
U: Unicode 字符串
4: 表示数据类型的大小（以字节为单位）。
4 表示每个元素占用 4 个字节。
对于有符号整数，i4 表示一个 32 位（4 字节）的有符号整数
范围为 -2,147,483,648 到 2,147,483,647。

多字节数据在内存中的存储顺序
大端模式
内存地址: 0x00 0x01 0x02 0x03
存储内容: 0x12 0x34 0x56 0x78

小端模式
内存地址: 0x00 0x01 0x02 0x03
存储内容: 0x78 0x56 0x34 0x12
'''
dt = np.dtype(int)
\#dt = np.dtype(np.int32)节省内存
arr = np.array([1,2,3],dtype=dt)
print(dt)
\#定义复杂结构
dt = np.dtype([('name','U10'),('age','int32')]) #定义结构化数据类型
data = np.array([('alice',25,('bob',32))],dtype = dt)
print(data)

print(data['name'])
print(data['age'])

\#数组属性
\#dimension ndim
a = np.arange(24)
print(a.ndim)
print(a.ndim)
b = a.reshape(2,4,3)
print(b.ndim)
\#shape
a = np.array([[1,2,3],[4,5,6]])
print(a.shape)
\#调整大小
a.shape = (3,2)
\#调整数组大小
a.reshape(3,2)
\#itemsize
\#以字节形式返回数组中的每一个元素的大小
x = np.array([1,2,3,4,5],dtype = np.int8)
\#x = np.array([1,2,3,4,5],dtype = np.float64)
print(x.itemsize)
\#flag 返回ndarray对象的内存信息
\#创建数组
'''
shape
dtype
order C 行优先 F 列有限

'''
\#empty 创建一个未初始化的数组
x = np.empty((3,2),dtype = int)
\#zeros create an array of zeros
np.zeros((5,),dtype = float,order = 'C')
\#ones create an array of ones
x = np.ones((3,2),dtype = int)
\#numpy.zeros_like
\#创建一个与给定数组具有相同形状的数组以0填充
\#zeros直接指定
arr = np.array([[1,2,3],[4,5,6]])
zeros_arr = np.zeros_like(arr)
print(zeros_arr)
\#numpy.ones_like
\#创建一个与给定数组具有相同形状的数组以1填充
arr = np.array([[1,2,3],[4,5,6]])
ones_arr = np.ones_like(arr)

\#从已有数组中创建数组
\#将列表转换为ndarray
x = [1,2,3]
x = (1,2,3)
a = np.asarray(x)

\#动态数组frombuffer
\#将缓冲区转换为ndarray
\#py3 默认str Unicode str前b bytestring
\#[b'H' b'e' b'l' b'l' b'o' b' ' b'W' b'o' b'r' b'l' b'd']
s = b'Hello World'
a = np.frombuffer(s,dtype = 'S1')
print(a)
\#fromiter
list = range
it = iter(list)
x = np.fromiter(it,dtype = float)
\#array 和 asarray 的区别 array会复制数据 asarray直接使用原数据内存
\#从数值范围创建数组
x = np.arange(10)
\#等差数列
a = np.linspace(0,1,10,endpoint = False)
\#等比数列
a = np.logspace(0,1,10)

\#切片和索引
a = np.arange(10)
s = slice(2,7,2)
print(a[s])
\#可替换为以下
s = a[2:7:2]
print(s)

a = np.array([[1,2,3],[3,4,5],[4,5,6]])
print(a[...,1])
print(a[1,...])
print(a[...,1:])

\#高级索引
\#整数数组索引
x = np.array([[1,2],[3,4],[5,6]])
rows = np.array([[0,0],[3,3]])
\#布尔索引
x = np.array([[0,1,2],[3,4,5]])
print(x)
print(x[x >5])

\#过滤 ~取补运算符
a = np.array([np.nan,1,2,np.nan,3,4,5])
print(a[~np.isnan(a)])
\#过滤非复数
print(a[np.iscomplex(a)])

\#花式索引
\#花式索引指的是利用整数数组进行索引。
\#使用索引数值的值作为目标数组的某个轴的下标来取值
\#一维数组 axis = 0
x = np.arange(9)
print(x)
x2 = x[[0,6]]
print(x2)

\#二维数组
x = np.arange(32).reshape((8,3))
print(x)
\#按指定顺序提出指定
print(x[[4,2,1,7]])
\#按相反顺序提出指定
x = np.arange(32).reshape((8,4))
print(x[[-4,-2,-1,-7]])

\#np.ix_ 函数就是输入两个数组，产生笛卡尔积的映射关系。
'''
A={a,b}, B={0,1,2}
A×B={(a, 0), (a, 1), (a, 2), (b, 0), (b, 1), (b, 2)}
B×A={(0, a), (0, b), (1, a), (1, b), (2, a), (2, b)}
'''
x = np.arange(32).reshape((8,4))
print(x[np.ix_([1,5,7],[0,3])])

\#广播broadcast
\#广播(Broadcast)是 numpy 对不同形状
\# (shape)的数组进行数值计算的方式，
\# 对数组的算术运算通常在相应的元素上进行。

\#a与b数组对应位相乘，维数相同 各维度长度相同
a = np.array([1,2,3,4])
b = np.array([5,6,7,8])
c = a * b
print(c)

\#两个数组的形状不同时，自动触发广播机制
a = np.array([1,2,3,4])
b = np.array([0,1,2])
print(a + b)
\#相当于把数组b在二维上做四次运算
a = np.array([[ 0, 0, 0],
[10,10,10],
[20,20,20],
[30,30,30]])
b = np.array([1,2,3])
bb = np.tile(b, (4, 1)) # 重复 b 的各个维度
print(a + bb)

\#迭代数组
a = np.arange(6).reshape(2,3)
print(a)
for x in np.nditer(a):
print(x,end=",")

\#转置
'''
默认情况下，
np.nditer 会按照数组的实际存储顺序（
内存布局）来访问元素。

转置操作 a.T 并不会真正改变数组的内存布局
，而是通过调整索引来实现转置效果

a.T 的内存布局仍然是按原始数组 a 的 C 风格存储顺序。


原始数组是：
[[ 0 5 10 15]
[20 25 30 35]
[40 45 50 55]]


原始数组的转置是：
[[ 0 20 40]
[ 5 25 45]
[10 30 50]
[15 35 55]]


以 C 风格顺序排序：
[[ 0 20 40]
[ 5 25 45]
[10 30 50]
[15 35 55]]
0, 20, 40, 5, 25, 45, 10, 30, 50, 15, 35, 55,

以 F 风格顺序排序：
[[ 0 20 40]
[ 5 25 45]
[10 30 50]
[15 35 55]]
0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55,
'''
a = np.arange(6).reshape(2,3)
for x in np.nditer(a.T):
print(x,end=",")
print('\n')
for x in np.nditer(a.T.copy(order = 'C')):

print(x,end=",")
print('\n')

for x in np.nditer(a):
print (x, end=", " )
for x in np.nditer(a.T.copy(order='C')):
print (x, end=", " )

c = b.copy(order='C')
b = a.T

\#显式设置#默认打横创建
a = np.arange(0,60,5)
a = a.reshape(3,4)
for x in np.nditer(a, order = 'C'):
print (x, end=", " )
for x in np.nditer(a, order = 'F'):
print (x, end=", " )


\#修改数组中元素的值
\#op_flags=['readwrite'] 读写模式
\#writeonly
a = np.aragenge(0,60,5)
a = a.reshape(3,4)
for x in np.nditer(a,op_flags=['readwrite']):
x[...]=2*x
print(a)

\#或者不原地修改则
b = a * 2
print(b)

\#广播迭代
'''
第一个数组为：
[[ 0 5 10 15]
[20 25 30 35]
[40 45 50 55]]


第二个数组为：
[1 2 3 4]


修改后的数组为：
0:1, 5:2, 10:3, 15:4, 20:1,
25:2, 30:3, 35:4, 40:1, 45:2, 50:3, 55:4,
'''
for x,y in np.nditer([a,b]):
print ("%d:%d" % (x,y), end=", " )

\#数组操作
\#reshape
a = np.arange(8)
b = a.reshape(2,4)

\#flat
a =np.arange(9).reshape(3,3)
for row in a:
print(row)
for element in a.flat:
print(element)

\#flatten
a = np.arange(8).reshape(2,4)
print(a.flatten())
print(a.flatten(order = 'F'))

\#RAVEL
print(a.ravel())(prder = 'F')

\#transpose
\#对换数组的维度

print(np.transpose(a))
print(a.T)

\#两种调用方式
print(np.average(a))
print(a.average())

\#rollaxis
a = np.arange(8).reshape(2,2,2)
print(np.where(a == 6))
print(a[1,1,0])

b = np.rollaxis(a,2,0)
print(b)
c = np.rollaxis(b,0,3)
'''
axis 轴 x,y,z 轴
a = (3,4,5)
代表深度 高度 宽度
轴就是0 1 2
rollaxis(a,2,0)
a 目标多维数组
axis 2 转到 0 轴
axis 0 转到 2 轴
将第2轴宽度滚动到第0轴深度
'''


\#swapaxes
a = np.arange(8).reshape(2,2,2)
b = np.broadcast(x,y)
r,c = b.iters

\#concatenate
print(np.concatenate((a,b),axis=0))
'''
第一个数组：
[[1 2]
[3 4]]


第二个数组：
[[5 6]
[7 8]]


沿轴 0 连接两个数组：
[[1 2]
[3 4]
[5 6]
[7 8]]


沿轴 1 连接两个数组：
[[1 2 5 6]
[3 4 7 8]]
'''

\#轴的定义
'''
轴0 行
轴1 列
轴2 深度
内层维度 2x3矩阵中每一行有四个元素

'''

\#stack
print(np.stack((a,b),axis=0))

\#split
\#hsplit
\#vsplit

\#数组的添加与删除

\#resize
\#横向下挤压
\#如果不够就重复
b = np.resize(a,(3,4,5))

\#append
\#insert
print(np.insert(a,1,[11],axis = 0))
\#未传递 Axis 参数。 在删除之前输入数组会被展开。
\#delete
\#unique
\#位运算
\#字符串函数
\#数学函数
np.around(a,decimals = 1)
\#舍入的小数位数。 默认值为0。
\# 如果为负，整数将四舍五入到小数点左侧的位置

\#算数函数
\#统计函数

print(np.amax(a,axis = 0))
print(np.ptp(a,axis = 0))
\#标准差
print(np.std([1,2,3,4]))
\#方差
print(np.var([1,2,3,4]))

\#排序
dt = np.dtype([('name','S10'),('age',int)])
a = np.array([("raju",21),("anil",25),("ravi",17),("amar",27)],dtype = dt)
print(np.sort(a,axis = 0))
print(np.argsort(a,axis = 0))

\#where
\#查询满足条件
\#字节交换
\#numpy 副本和视图
\#numpy中的赋值时地址
\#两个数组变化在另一个数组
\#线性代数
\#numpy oi
\#二进制格式保存
np.save('outfile.npz,a')
np.savez('num.npz',a,b,sin_array = c)
r = np.load('num.npz')
print(r.files)
print(r["arr_0"])
print(r["arr_1"])

\#savetxt()
\#简单的文本格式存储
a = np.array([1,2,3,4,5])
np.savetxt('out.txt',a)
b = np.loadtxt('out.txt')

np.savetxt("out.txt",a,fmt="%d",delimiter=",") # 改为保存为整数，以逗号分隔
b = np.loadtxt("out.txt",delimiter=",") # load 时也要指定为逗号分隔

# pandas

import pandas as pd
import numpy as np

\#pandas
'''
数据清洗
数据转换
数据分析
数据可视化
'''
\#series 一维数组
\#datframe 表格
data = {'name':['goole','runoob','taobao'],'age':[25,30,35]}
df = pd.DataFrame(data)
print(df)

series_apples = pd.Series([1,2,3,4])
series_bananas = pd.Series([5,6,7,8])

df = pd.DataFrame({'apples':series_apples,'bananas':series_bananas})
print(df)

\#series
series = pd.Series([1,2,3,4,5])
custom_index = [1,2,3,4]
series_with_index = pd.Series([1,2,3,4,5],index=custom_index)
a = [1,2,3]
myvar = pd.Series(a)
print(myvar)
print(myvar[1])
a = ["goole","wiki","runoob"]
myvar = pd.Series(a,index = ["x","y","z"])
print(myvar)

sites = {1:"goole",2:"runoob",3:"wiki"}
myvar = pd.Series(sites,index = [1,2,3])
print(myvar)

result = series * 2
filtered_series = series[series > 3]
result = np.sqrt(series)

data = [['goole',10],['runoob',12],['wiki',13]]
df = pd.DataFrame(data,columns=['name','age'])
print(df)

\#pandas
df = pd.DataFrame(data)
print(df.loc[[0,1]])

\#索引
data = {
"calories": [420, 380, 390],
"duration": [50, 40, 45]
}
df = pd.DataFrame(data, index = ["day1", "day2", "day3"])
print(df)
print(df.loc['row1'])

\#查看
print(df.describe())
\#获取统计信息
print(df.describe())
\#排序
\#查看前两行数据
print(df.head(2))
\#查看dataframe的基本信息
print([http://df.info()](http://link.zhihu.com/?target=http%3A//df.info()))
\#查看最后两行数据
print(df.tail(2))
\#by按照指定列 ascengding升序/descending降序
df_sorted = df.sort_values(by = 'Score',ascending = False)
\#按索引选择行
print(df.iloc[1:3])
\#按标签选择行
print(df.loc[1:2])
\#计算分组统计 计算平均年龄
print(df.groupby('name')['age'].mean())
\#处理缺失值
df['age'] = df['age'].fillna(30)
\#导出为csv
df.to_csv('out.csv',index=False)

\#dataframe
df = pd.DataFrame({'column1':[1,2,3,4,5],'column2':[6,7,8,9,10]})
\#dataframe 的属性和方法
print(df.shape)
print(df.columns)
print(df.index)
print(df.values)

df.loc[3] = [11,12]
df.loc[4] = [13,14]
df.loc[5] = [15,16]

new_row = {'Column1': 13, 'Column2': 14, 'NewColumn': 16}
df = df.append(new_row, ignore_index=True)
print(df)

df['Column1'] = df['Column1'].astype('float64')
pd.concat([df,df],axis=1)


df_pivot = df.pivot(index ='column1',columns = 'column2',values='column3')
df_melt = pd.melt(df,id_vars=['column1'],value_vars=['column2','column3'])


\#csv
df = pd.read_csv('data.csv',sep=';',header=0,names=['a','b'],dtype={'a':str,'b':int})
print(df)

df = pd.read_csv('nba.csv')
print(df.to_string())

df.to_csv('out.csv',index=False,header=True,columns=['a','b'])
df =pd.DataFrame(dict)

nme = ["Google", "Runoob", "Taobao", "Wiki"]
st = ["[http://www.google.com](http://link.zhihu.com/?target=http%3A//www.google.com)", "[http://www.runoob.com](http://link.zhihu.com/?target=http%3A//www.runoob.com)", "[http://www.taobao.com](http://link.zhihu.com/?target=http%3A//www.taobao.com)", "[http://www.wikipedia.org](http://link.zhihu.com/?target=http%3A//www.wikipedia.org)"]
ag = [90, 40, 80, 98]

df = pd.DataFrame(dict)
df.to_csv('site.csv')

\#head()
\#读取前面几行
\#返回5行
\#tail()
\#读取尾部n行 返回5行
\#info()

\#excel
df = pd.read_excel('data.xlsx',sheet_name='Sheet1')
print(df)

\#写入多个表单 使用excelwriter
with pd.ExcelWriter('output.xlsx') as writer:
df.to_excel(writer,sheet_name='sheet1',index=False)
df.to_excel(writer,sheet_name='sheet2',index=False)
excel_writer = pd.ExcelWriter('output.xlsx')

excel_file = pd.ExcelFile('data.xlsx')
df = excel_file.parse('sheet1')
excel_file.close()

\#创建excelwriter
with excel_writer as writer:
df.to_excel(writer,sheet_name='sheet1',index=False)
df.to_excel(writer,sheet_name='sheet2',index=False)

'''
openpyxl
专门用于读写 Excel .xlsx 文件的 Python 库
或者使用xlswriter
'''
\#使用if_sheet_exists参数替换已存在的表单
with excel_writer(
"path_to_file.xlsx",
mode='a',
engine="openpyxl",
if_sheet_exists="replace"

)as writer:
df.to_excel(writer,sheet_name="sheet1")


import zipfile
df = pd.DataFrame([["ABC", "XYZ"]], columns=["Foo", "Bar"])
with zipfile.ZipFile("path_to_file.zip", "w") as zf:
with zf.open("filename.xlsx", "w") as buffer:
with pd.ExcelWriter(buffer) as writer:
df.to_excel(writer)

\#向底层引擎传递额外参数
engine_kwargs = {"mode": "a", "if_sheet_exists": "replace"}

engine_kwargs = {"keep_vba":True}

\#json
df =pd.read_json('data.json')
data =[
{
"id": "A001",
"name": "菜鸟教程",
"url": "[http://www.runoob.com](http://link.zhihu.com/?target=http%3A//www.runoob.com)",
"likes": 61
},
{
"id": "A002",
"name": "Google",
"url": "[http://www.google.com](http://link.zhihu.com/?target=http%3A//www.google.com)",
"likes": 124
},
{
"id": "A003",
"name": "淘宝",
"url": "[http://www.taobao.com](http://link.zhihu.com/?target=http%3A//www.taobao.com)",
"likes": 45
}
]
df = pd.DataFrame(data)

print(df)

\#将python字典转化为dataframe
'''
\#这是用于定义多行字符串并不是注释，但是如果
没有赋值或使用，python会忽略他们
'''
json_data = '''
[
{"Name": "Alice", "Age": 25, "City": "New York"},
{"Name": "Bob", "Age": 30, "City": "Los Angeles"},
{"Name": "Charlie", "Age": 35, "City": "Chicago"}
]
'''
\#orient='records'：指定 JSON 数据的格式。
\# 'records' 表示 JSON 数据是一个记录列表
\# （即每个字典是一条记录）。
df = pd.read_json(json_data,orient='records')
print(df)

\#内嵌的json数据
\#pd.json_normalize()展平
import pandas as pd
import json
with open('nested_list.json','r') as f:
data = json.loads(f.read())

df_nested_list = pd.json_normalize(data,record_path = ['students'])
print(df_nested_list)

\#glom模块 访问内嵌对象的属性

\#数据清洗
\#删除包含缺失值的行或列
df.dropna(inplace=True)
\#删除重复的行
df.drop_duplicates(inplace=True)
df.fillna(0)
df.replace('old_value','new_value',inplace=True)
\#检查是否重复
df.duplicated()
\#删除重复的数据
df.drop_duplicates()

\#数据切片和选择
df['column_name']
\# df.loc[row_index,column_name]

\# df.iloc[row_index,column_index]
\# df.ix[row_index,column_name]
\#按照指定列的值
df.sort_values('column_name')
\#按照多个列的值
df.sort_values(['column_name1','column_name2'],ascending=[True,False])
\#按照索引排序
df.sort_index()
\#按照指定列排序
df.groupby('column_name')
\#分组后数据求均值
df.aggregate('function_name')
\#透视表
df.pivot_table(index='column_name1',columns='column_name2',values='column_name3')
\#合并数据
\#多个数据框按照行列合并
\#df = pd.concat([df1,df2],axis=0)
\#指定列将两个数据框合并
\#df = pd.merge(df1,df2,on='column_name',how='inner')

\#pearson
\#皮尔逊相关系数：
\# 衡量变量之间的线性关系，适用于数值型变量。
correltion = df.corr(method='pearson')
\#斯皮尔曼等级相关系数：
\# 衡量变量之间的单调关系，适用于数值型和顺序型变量。
correltion = df.corr(method='spearman')
correltion = df.corr()


\#seaborn库
import seaborn as sns
import matplotlib.pyplot as plt
\#绘制热力图
\#大小
plt.figure(figsize=(8, 6))
\#sns.heatmap() 绘制相关性热图
\# annot=True 表示在热图上显示数值
\# cmap='coolwarm' 设置颜色范围
\# vmin=-1, vmax=1 限制颜色范围为 -1 到 1。
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1)
plt.title('Correlation Heatmap')
plt.show()

\#排序
df_sorted = df.sort_values(by='age',ascengding=False)
print(df_sorted)

\#数据聚合
\#聚合函数
\#sum(), mean(), count(), min(), max(), std()
grouped = df.groupby('department')['salary'].mean()
print(grouped)
\#多重聚合函数
grouped = df.groupby('department')['salary'].agg(['mean','std'])
grouped = df.groupby('department').agg({'salary':['mean','std']})

print(grouped)

\#分组后的排序
grouped = df.groupby('department')['salary'].mean().sort_values(ascending=False)

\#透视表
pivot_table = df.pivot_table(values = 'salary',index = 'department',aggfunc='mean')
print(pivot_table)

\#数据可视化
\#折线图
import pandas as pd
import matplotlib.pyplot as plt

data = {'Year': [2015, 2016, 2017, 2018, 2019, 2020],
'Sales': [100, 150, 200, 250, 300, 350]}
df = pd.DataFrame(data)

df.plot(kind='line',x = 'Year',y='Sales',title = 'sales over years',xlabel='Year',ylabel='Sales',ylabel = 'Sales',figsize=(10,6))

plt.show()

\#柱状图
data = {'Category': ['A', 'B', 'C', 'D'],
'Value': [10, 15, 7, 12]}
df = pd.DataFrame(data)

df.plot(kind='bar',x='Category',y='Value',title='Category vs Value',xlabel='Category',ylabel='Value',figsize=(10,6))
'''
kind
x
y
title
xlabel
ylabel
figsize
'''

'''
line 折线图
bar 条形图
barh 水平条形图
hist 直方图
scatter 散点图
box 箱线图
pie 饼图
'''

\#seaborn
\#heatmap
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

data = {'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}
df = pd.DataFrame(data)

\# 绘制热力图
\#热力图
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.show()

\#散点图
sns.pairplot(df)

\#matplotlib
data = {'Year': [2015, 2016, 2017, 2018, 2019],
'Sales': [100, 150, 200, 250, 300]}
df = pd.DataFrame(data)

\# 绘制折线图
plt.plot(df['Year'], df['Sales'], color='blue', marker='o')

\# 自定义
plt.title('Sales Over Years')
plt.xlabel('Year')
plt.ylabel('Sales')
plt.grid(True)

\# 显示
plt.show()

\#pandas 高级功能
left = pd.DataFrame({'ID': [1, 2, 3], 'Name': ['Alice', 'Bob', 'Charlie']})
right = pd.DataFrame({'ID': [1, 2, 4], 'Age': [24, 27, 22]})

\# 使用 merge 进行内连接
result = pd.merge(left, right, on='ID', how='inner')
print(result)

df1 = pd.DataFrame({'a':[1,2,3]})
df2 = pd.DataFrame({'b':[4,5,6]})
df3 = pd.DataFrame({'c':[7,8,9]})

result = pd.concat([df1,df2],axis=0,ignore_index=True)
print(result)

result = left.join(right,how='inner')
print(result)

\#透视表和交叉表
pivot_table()
pivot_table = pd.pivot_table(df,values='sales',index='date',columns='category',aggfunc='sum',fill_value=0)
cross_table = pd.crosstab(df['category'],df['region'])
print(cross_table)

\#自定义函数
\#数据清洗和转换
def custom_func(x):
return x * 2
df['a'] = df['a'].apply(custom_func)
print(df)

\#applymap()

import pandas as pd
df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})
df = df.applymap(lambda x: x ** 2)

\#map()
df = pd.DataFrame({'A': ['a', 'b', 'c'], 'B': [1, 2, 3]})
df['A'] = df['A'].map({'a': 'A', 'b': 'B', 'c': 'C'})
'''
无字典映射
A
0 kitten
1 puppy
2 NaN

有字典映射
A
0 cat
1 dog
2 rabbit
'''

\#时间序列
\#生成时间序列
date_range = pd.date_range(start='2021-01-01', end='2021-01-31', freq='D')
print(date_range)

\#timedelta()
date = pd.to_datetime('2021-01-01')
new_date = date + pd.Timedelta(dayes=10)

\#时间和日期的偏移
date = pd.to_datetime('2021-01-01')
new_date = date + pd.DateOffset(months=1)
print(new_date)

df = pd.DataFrame({'Value': [10, 20, 30, 40, 50]})

\# 计算 3 天滚动平均
df['Rolling_Mean'] = df['Value'].rolling(window=3).mean()
print(df)

\#缺失值
df_filled = df.fillna(0)

\#优化
df['category'] = df['category'].astype('category')

\#pandas 避免使用python的原生循环
df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})
df['c'] = df['A'] + df['B']
print (df)

\#分块加载大数据
\#chunksize
def process():
\# 处理 chunk
pass

chunksize = 100000
for chunk in pd.read_csv('data.csv', chunksize=chunksize):
process(chunk)

\#dask vaex 可以支持多线程和分布式运算
import dask.dataframe as dd
df = dd.read_csv('data.csv')

\#numba
import numba
import numpy as np
@numba.jit
def caculate(x):
return x ** 2

df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})
df['C'] = df['A'].apply(caculate)
print(df)
\#避免链式赋值
\#避免再同一行中多次赋值

# matplotlib

from matplotlib import pyplot as plt
\#基础功能
x = [1, 2, 3, 4, 5]
y = [2, 4, 6, 8, 10]
\#设置图片大小 要放到show前面
fig = plt.figure(figsize=(8, 6),dpi = 80)

plt.plot(x, y)
\#设置x轴的刻度
plt.xticks(range(2,25,0.5))
_xtick_labels = [i/2 for i in range(2,49)]
plt.xticks(_xtick_labels[::3])
plt.yticks(range(2,25,2))
plt.yticks(range(min(y),max(y)+1))
\#保存
plt.savefig('test.png')
plt.show()

\#pylab
from matplotlib import pyplot as plt
from pylab import *
from numpy import *

\#符号 '-'，'--'，'-.'，':'，'.'，','，，o，^，v，<，>，s，+，x，D，d，1，2，3，4，h，H，p，| ，_
\#颜色 b(蓝色)，g(绿色)，r(红色)，c(青色)，m(品红)，y(黄色)，k(黑色)，w(白色)
\#线宽 lw
\#点大小 ms
\#线类型 ls
\#标记类型 marker

\#画图
from pylab import *
x = linspace(-3, 3, 30)
y = x**2
plot(x, y, 'r.')
plot(x,sin(x),'r-')
show()
\#清除
clf()
\#新建画布
fig = plt.figure()
\#画轴
ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])
'''
figsize
dpi
facecolor
dgecolor
frameon
'''

\#完整
from matplotlib import pyplot as plt
import numpy as np

import math
x = np.arange(0, 2*math.pi, 0.1)
y = np.sin(x)
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
ax.plot(x,y)
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_title('Sine Wave')
plt.show()

axes.plot()
\#rgb cmyk

\#subplot() 均等的在一个画布上
\#画多个图
plt.plot([1,2,3])
plt.subplot(2,1,1)
\#或 两行一列绘制在第一个位置
plt.subplot(211)
\#不想覆盖
ax1 = plt.add_subplot(211)
\#axes对象 在同一画布上插入另外图像
axes1 = fig.add_axes([0.1, 0.1, 0.8, 0.8])
\#subplots
import matplotlib.pyplot as plt
fig,a = plt.subplots(2,2)
import numpy as np
x = np.arange(1,5)
\#绘制平方函数
a[0][0].plot(x,x*x)
a[0][0].set_title('square')
\#绘制平方根图像
a[0][1].plot(x,np.sqrt(x))
a[0][1].set_title('square root')
\#绘制指数函数
a[1][0].plot(x,np.exp(x))
a[1][0].set_title('exp')
\#绘制对数函数
a[1][1].plot(x,np.log10(x))
a[1][1].set_title('log')
plt.show()

\#subplot2grid()
\#非等分

a1 = plt.subplot2grid((3,3),(0,0),colspan = 2)
a2 = plt.subplot2grid((3,3),(0,2), rowspan = 3)
a3 = plt.subplot2grid((3,3),(1,0),rowspan = 2, colspan = 2)

\#设置网格格式
\#创建一行三列
fig, axes = plt.subplots(1,3, figsize = (12,4))

axes[0].plot(x, x**3, 'g',lw=2)
axes[1].grid(color='b', ls = '-.', lw = 0.25)
axes[2].plot(x,x)
\#开启网格
axes[0].grid(True)
\#设置标签和轴线的距离
axes[0].xaxis.labelpad = 10

\#坐标轴格式
axes[1].set_yscale("log")
\#设置刻度标签

\#解决乱码问题
import matplotlib.pyplot as plt
plt.rcParams["font.sans-serif"] = ["SimHei"]
plt.rcParams["axes.unicode_minus"] = False
ax.set_xticklabels(['zero','two','four','six'])
ax.set_yticks([-1,0,1])

\#双轴图
fig = plt.figure()

a1 = fig.add_axes([0,0,1,1])
a1.plot(x,np.exp(x))
a1.set_ylabel('exp')

a2 = a1.twinx()
a2.plot(x,np.log(x),'ro-')
a2.set_ylabel('log')

fig.legend(labels = ('exp','log'),loc = 'upper left')
plt.show()

\#柱状图
fig = plt.figure()

langs = ['C', 'C++', 'Java', 'Python', 'PHP']
students = [23,17,35,29,12]

ax.bar(langs,students)
plt.show()

\#多个直方图

data =[[30, 25, 50, 20],[40, 23, 51, 17],[35, 22, 45, 19]]
X = np.arange(4)
fig = plt.figure()
\#添加子图区域
ax = fig.add_axes([0,0,1,1])
'''
[0,0,1,1] 是一个包含四个元素的列表，分别表示左、下、宽、高四个属性：
左：坐标轴左边与图形左边界的距离比例，值为0表示紧贴左边。
下：坐标轴底边与图形底边的距离比例，值为0表示紧贴底部。
宽：坐标轴的宽度占整个图形宽度的比例，值为1表示占据全部宽度。
高：坐标轴的高度占整个图形高度的比例，值为1表示占据全部高度。
'''



ax.bar(X + 0.00, data[0], color = 'b', width = 0.25)
ax.bar(X + 0.25, data[1], color = 'g', width = 0.25)
ax.bar(X + 0.50, data[2], color = 'r', width = 0.25)

\#绘制堆叠图

countries = ['USA', 'India', 'China', 'Russia', 'Germany']
bronzes = np.array([38, 17, 26, 19, 15])
silvers = np.array([37, 23, 18, 18, 10])
golds = np.array([46, 27, 26, 19, 17])

'''
enumerate(countries) 会生成 [(0, 'China'), (1, 'USA'), (2, 'Japan')]
'''
ind = [x for x, _ in enumerate(countries)]

plt.bar(ind, golds, width=0.5, label='golds', color='gold', bottom=silvers+bronzes)
plt.bar(ind, silvers, width=0.5, label='silvers', color='silver', bottom=bronzes)
plt.bar(ind, bronzes, width=0.5, label='bronzes', color='#CD853F')

\#小提琴
\#bp = ax.violinplot(data_to_plot)

\#绘制三维图像
ax = plt.axes(projection='3d')

\#从三个维度构建
z = np.linspace(0, 1, 100)
x = z * np.sin(20 * z)
y = z * np.cos(20 * z)

\#调用 ax.plot3D创建三维线图
ax.plot3D(x, y, z, 'gray')
ax.set_title('3D line plot')
plt.show()

\#完整
from mpl_toolkits import mplot3d
import numpy as np
import matplotlib.pyplot as plt

fig = plt.figure()
ax = plt.axes(projection='3d')

z = np.linspace(0, 1, 100)
x = z * np.sin(20 * z)
y = z * np.cos(20 * z)

ax.plot3D(x, y, z, 'gray')
ax.set_title('3D line plot')
plt.show()

\#3d 散点图
\#ax.scatter3D(x, y, z, c=c)

\#等高线
\#ax.contour3D(X, Y, Z, 50, cmap='binary')

\#3d 曲面
\#ax.plot_surface(x, y, z,cmap='viridis', edgecolor='none')

\#文书
\# Text Markup
\#文本标记符放到美元符号
\#plt.title(r'$\alpha > \beta$')
\#绘制下标和上标，您需要使用'_'和'^'符号
\#ax.text(3, 8, 'C语言中网网编程爱好者都喜欢的网站', style='italic',bbox = {'facecolor': 'yellow'},fontsize=15)
\#ax.annotate('C语言中文网', xy = (2, 1), xytext = (3, 4),arrowprops = dict(facecolor = 'blue', shrink = 0.1))

\#matplotlib image
\#目前只支持png
\#通常使用pillow来处理图像

import matplotlib.image as mpimg
img = mpimg.imread('mtplogo.png')
\#lower 实现翻转
plt.imsave("logo.png", img, cmap = 'gray', origin = 'lower')

# 数据分析与挖掘

\#数据探索

\#数据校验

\#一致性分析
\#时间校验
\#缺失值校验
import pandas as pd
data = pd.read_csv('data.csv')
print('计算空值',data.isnull())
data.notnull()
data.isna()
data.DataFrame.count(axis=0,numeric_only=False)

\#异常值
import numpy as np
ary = (99999,5700,53, 50, 56, 59, 51, 54, 57)

\#使用Iqr算法
Percentile = np.percentile(ary,[0,25,50,75,100])
IQR = Percentile[3] - Percentile[1]
UpLimit = Percentile[3] + 1.5 * IQR
arrayownmLimit = Percentile[3] - 1.5 * IQR
abnormal = [i for i in ary if i > UpLimit or i < arrayownmLimit]

print(abnormal)
print(len(abnormal) / len(ary))


\#使用3倍标准差算法
array_mean = np.array(ary).mean()
array_sarray = np.array(ary).std()
array_cha = ary - array_mean

ind = [i for i in range(len(array_cha)) if np.abs(array_cha[i]) > 3 * array_sarray]
abnormal = [ary[i] for i in ind]

print(abnormal)
print(len(abnormal) / len(ary))


\#describe()方法 查看数据基本情况
data = pd.read_csv('data.csv',index_col='id')
print(data.describe())


\#箱线图
import matplotlib.pyplot as plt
\#显示中文标签
plt.rcParams['font.sans-serif'] = ['SimHei']
\#正常显示负号
plt.rcParams['axes.unicode_minus'] = False

plt.figure()
p = data.boxplot(return_type = 'dict')

x = p['fliers'][0].get_xdata()
y = p['fliers'][0].get_ydata()
\#直接改变原对象
y.sort()

for i in range(len(x)):
if i > 0:
plt.annotate(y[i], xy=(x[i], y[i]), xytext=(x[i] + 0.05 - 0.8 / (y[i] - y[i - 1]),y[i]))
else:
plt.annotate(y[i], xy=(x[i], y[i]), xytext=(x[i] + 0.08, y[i]))
plt.rc('font',size=10)
plt.show()

\#数据特征分析

'''
集中趋势度量
均值
中位数
众数
'''

'''
离中趋势度量
极差
标准差
变异系数
四分位数间距
'''

\#分布分析
'''
1.定量分析
求极差
决定组距组数
决定分布区间
列出频率分布表
绘制直方图
2.定性数据分析
'''
import pandas as pd
import matplotlib.pyplot as plt
data = pd.read_csv('data.csv',index_col='id')

x = data['销售额']
labels = data['菜系']
\#饼图
plt.pie(x,labels= labels,autopct='%1.1f%%',labeldistance = 1.1,pctdistance = 1.1)

\#对比分析
'''
绝对数比较
相对数比较
结构相对数
比例相对数
比较相对数
强度相对数
'''

\#绘制不同部门各月份对比折线图
import pandas as pd
import matplotlib.pyplot as plt

data = pd.read_excel('data.xlsx')

plt.figure(figsize=(6,4))
\#先x轴再y轴
\#markers s 方块
plt.plot(data['月份'],data['部门A'],label='部门A',color='red',markers = 's')
plt.plot(data['月份'],data['部门B'],label='部门B',color='green',markers = 'o')
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.legend()
plt.title('部门销售对比')
plt.xlabel('月份')
plt.ylabel('销售额')
plt.grid()
plt.xticks(rotation=45)

plt.show()

\#周期性分析
normal = pd.read_excel('data.xlsx')

\#获取当前axes对象 以便对后续操作
\#一个figure可以包含一个或多个axes 一个axess 对象包含一个或多个子图
ax = plt.gca()

ax.legend()

ax.set_titlke('周期性分析')


\#设置x轴主刻度定位器
\#设置x轴间刻度每隔一个单位（即 1）设置一个主刻度。
x_major_locator = plt.MultipleLocator(1)
\#将创建的主刻度定位器应用到 ax 的 x 轴。
ax.xaxis.set_major_locator(x_major_locator)

plt.tight_layout()

\#贡献度分析
data = pd.read_excel('data.xlsx',index_col='服装名')
data = data['月份'].copy()
data.sort_values(ascending=False)


p = 2.0 * data.cumsum() / data.sum()
p.plot(color='red',secondary=True,style='--',linewidth=2)
plt.annotate(format(p[6],'4%'),xy = (6,p[6]),xytext = (6 * 0.9,p[6] * 0.9)
,arrowprops = dict(arrowstyle = '->',connectionstyle = 'arc3',rad='0.4'))

\#corr()
import pandas as pd
data = pd.read_csv('data.csv',index_col='id')
print(data.corr())
print(data.corr()['销售额'])

\#数据预处理
\#数据清洗

\#列表去重
data = pd.read_csv('data.csv',index_col='id')
def delRep(list1):
list2 = []
for i in list1:
if i not in list2:
list2.append(i)
return list2

names = list(data['id'])

\#集合去重
\#set()去做去重会影响排序
names = data['id'].drop_duplicates()
\#多列去重
print('去重前：',data.shape)
shape = data.drop_duplicates(subset=['id','菜系'],keep='first').shape
print('去重后：',shape)


\#属性去重
def FeatureEquals(df):
dfEquals = pd.DataFrame([],columns=df.columns,index=df.columns)
for i in df.columns:
for j in df.columns:
if i != j:
dfEquals.loc[i,j] = df.loc[:,i].equals(df.loc[:,j])
return dfEquals

det = FeatureEquals(data)

\#筛选出完全重复的属性
l = det.shape[0]
d = []
for k in range(1):
for l in range(k+1,1):
if det.iloc[k,l] & (det.column[l] not in d):
d.append(det.columns[l])
print('需要删除的列',d)
data.drop(d,axis=1,inplace=True)
print(data.shape[1])

\#缺失值处理
\#常见插补方法
\#均值插补
\#回归
\#拉格朗日插值法
\#牛顿插值法

\#拉格朗日插值法
import pandas as pd
from scipy.interpolate import lagrange

data = pd.read_csv('data.csv',index_col='id')

def ployinterp_column(s,n,k=5):
y = s.reindex(list(range(n - k,n)) + list(range(n + 1,n + k + 1)))
y = y[y.notnull()]
return lagrange(y.index,list(y))(n)

for i in data.columns:
for j in range(len(data)):
if (data[1].isnull())[j]:
data[i][j] = ployinterp_column(data[i],j)
print(data)



\#修正异常值
\#删除含有异常值的记录
\#视为缺失值
\#平均值修正

\#数据变换
\#简单函数变换
\#数据标准化
\#最小最大标准化
print((data - data.min()) / (data.max() - data.min()))
\#零均值标准化
print((data - data.min()) / data.std())
\#小数定标标准化
print(data / 10 ** np.ceil(np.log10(data.abs().max())))

\#数据离散化

\#等宽法
d1 = pd.cut(data,k,labels = range(k))

\#等频法
w = [1.0 * i / k for i in range(k+1)]

\#聚类离散化 一维
d3 = pd.cut(data,w,labels = range(k))

\#修正异常值
\#删除含有异常值的记录
\#视为缺失值
\#平均值修正

\#数据变换
\#简单函数变换
\#数据标准化
\#最小最大标准化
print((data - data.min()) / (data.max() - data.min()))
\#零均值标准化
print((data - data.min()) / data.std())
\#小数定标标准化
print(data / 10 ** np.ceil(np.log10(data.abs().max())))

\#数据离散化

\#等宽法
d1 = pd.cut(data,k,labels = range(k))

\#等频法
w = [1.0 * i / k for i in range(k+1)]

\#聚类离散化 一维
from sklearn.cluster import KMeans
kmodel = KMeans(n_clusters=k,n_jobs=4)
kmodel.fit(np.array(data).reshape(len(data),1))

c = pd.DataFrame(kmodel.cluster_centers_).sort_values(by=0)

w = c.rolling(2).mean()

w = [0] + list(w[0]) + [data.max()]

d3 = pd.cut(data,w,labels=range(k))

def cluster_plot(d,k):
import matplotlib.pyplot as plt
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.figure(figsize=(6,4))
for j in range(k):
plt.plot(data[d==j],[j for i in d[d==j]],'o')
plt.ylim(-0.5,k-0.5)
plt.rc('font',size=12)
return plt

cluster_plot(d3,k).show()
cluster_plot(d1,k).show()

\#独热编码
from sklearn import preprocessing
enc = preprocessing.OneHotEncoder()
enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])

print('[0,0,0]',enc.transform([[0, 0, 0]]).toarray())
print('[0,0,1]',enc.transform([[0, 0, 1]]).toarray())

\#数据合并
import numpy as np
import pandas as pd

\#横向堆叠 按照x轴连接起来
meal = pd.read_csv('meal.csv',index_col='id')
df1 = meal.iloc[:,:5]
df2 = meal.iloc[:,5:]

print('外连接',pd.concat([df1,df2],axis=1,join='outer').shape)
print('内连接',pd.concat([df1,df2],axis=1,join='inner').shape)

\#纵向连接
\#concat append
df3 = meal.iloc[:10,:]
df4 = meal.iloc[10:,:]
print('纵向连接',pd.concat([df3,df4],axis=0))
print('纵向连接append',df3.append(df4))

\#merge合并数据
info = pd.read_csv('info.csv',index_col='id')

info['id'] = info['info_id'].astype(int)
meal['id'] = meal['meal_id'].astype(int)

order_detail = pd.merge(meal,info,left_on='order_id',right_on='info_id')

print(meal.shape)
print(info.shape)
print(order_detail.shape)

info.rename(columns={'info_id':'id'},inplace=True)
meal['order_id'] = meal['order_id'].astype(int)
order_detail = meal.join(info,on='order_id',rsuffix='1')


\#重叠合并
\#conbine_first
a1 = {'id':[1,2,3,4,5]}
a2 = {'id':[1,2,3,4,5,6,7,8,9,10],
'name':['a','b','c','d','e','f','g','h','i','j']}

df2 = pd.DataFrame(a1)
df3 = pd.DataFrame(a2)
print('合并',df2.combine_first(df3))

\#groupby()
\#拆分
import pandas as pd
detail = pd.read_csv('detail.csv',index_col='id')
detailGroup = detail.groupby('order_id')

\#groupby()求均值标准差 大小
print('均值',detailGroup.mean())
print(detailGroup.std().head())

\#agg()
\#同属性不同统计量
print('',detail[['counts','amount']].agg(['mean','std']))
\#不同属性不同数目
print({'count':np.sum,'amount':[np.sum,np.mean]})

\#agg()自定义函数
def DoubleSum(data):
s = data.sum()
\#可使用numpy
s = np.sum(data)
return s * 2

print('',detail.agg({'counts':DoubleSum,'amount':DoubleSum},axis=0))

\#apply()只能作用于整体dataframe series
print('',detailGroup.apply(np.mean).head())

\#agg()可以对不同属性不同函数获取不同效果

print('',detail[['count','amount']].transform(lambda x:x * 2).head(4))
\#数据清理 数据变换 数据合并




\#数据挖掘算法基础
\#分类和回归

\#分类评估
\#准确率
\#判断准确占全部

\#精确率
\#所有预测为正占实际正的百分比

\#反馈率
\#准确预测为正占实际真样本

\#混淆矩阵
\#描绘样本预测与真实属性

\#roc曲线
\#纵坐标 准确预测正样本
\#横坐标 负样本预测为正样本

\#回归
\#绝对误差和相对误差
\#平均绝对误差
\#均方误差
\#均方根误差
\#kappa统计 多观测

\#线性模型
\#线性回归模型
\#逻辑回归模型

\#线性回归模型
import pandas as pd
data = pd.read_csv('data.csv',index_col='id')

from sklearn.linear_model import LinearRegression
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split

\#划分训练集和测试集
x = data.loc[:,'x':'y'].values
y = data.iloc[:-1].values

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)

\#建立回归模型
clf = LinearRegression().fit(x_train,y_train)

\#预测测试集结果
y_pred = clf.predict(x_test)
print('预测值',y_pred[:4])

from sklearn.metrics import r2_score,mean_squared_error,explained_variance_score,mean_absolute_error,median_absolute_error

print('平均绝对误差',mean_absolute_error(y_test,y_pred))
print('均方误差',mean_squared_error(y_test,y_pred))
print('中值绝对值',median_absolute_error(y_test,y_pred))
print('解释方差',explained_variance_score(y_test,y_pred))
print('boston',r2_score(y_test,y_pred))

\#逻辑回归模型
import pandas as pd
import numpy as np
from sklearn.linear_model import datasets
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder,StandardScaler,OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split

lris = datasets.load_iris()
x = lris.data
y = lris.target

label_encode = LabelEncoder()
y = label_encode.fit_transform(y)
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)

lr = Pipeline([('sc',StandardScaler()),('clf',LogisticRegression())])
lr.fit(x_train,y_train)

y_pred = lr.predict(x_test)
num_accu = np.sum(y_pred == y_test)
print('准确率',num_accu)
print('预测错误数',y_test.shape[0] - num_accu)
print('准确率',num_accu / y_test.shape[0])

\#决策树

import pandas as pd
sales_data = pd.read_excel('sales_data.xlsx')

sales_data[sales_data == '好'] = 1
sales_data[sales_data == '高'] = 1
sales_data[sales_data == '是'] = 1

sales_data[sales_data != 1] = -1

x = sales_data.iloc[:,:3].astype(int)
y = sales_data.iloc[:,3].astype(int)

from sklearn.tree import DecisionTreeClassifier as DTC
dtc = DTC(criterion = 'entroy')
dtc.fit(x,y)
y = dtc.predict(x)

from sklearn.tree import export_graphviz
x = pd.DataFrame(x)

with open('tree.dot','w') as f:
f = export_graphviz(dtc,out_file=f,feature_names=x.columns,out_file=f)
\#安装graphviz可视化

\#最近邻分类
'''
分类中投票法 选择k 个邻居中出现最多类别标记的预测结果
回归使用平均法 取k个邻居实际值 输出标记的平均值 或距离远近加权
'''

from sklearn.neighbors import KNeighborsClassifier as KNN
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split

digits = load_digits()
data = digits.data
target = digits.target
traindata,testdata,traintarget,testtarget = train_test_split(data,target,test_size=0.2,random_state=123)

model_knn = KNN(n_neighbors=5)
model_knn.fit(traindata,traintarget)

testtarget_pre = model_knn.predict(testdata)

print('前十条预测值为',testtarget_pre[:10])
print('前十条实际值',testtarget_pre[:10])

from sklearn.metrics import accuracy_score
print('准确率',accuracy_score(testtarget,testtarget_pre))


\#支持向量机
\#找到一个超平面划分二分类
\#线性支持向量机

from sklearn.svm import SVC
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split

digits = load_digits()
data = digits.data

target = digits.target

traindata,testdata,traintarget,testtarget = train_test_split(data,target,test_size=0.2,random_state=123)